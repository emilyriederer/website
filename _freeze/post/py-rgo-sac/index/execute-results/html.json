{
  "hash": "a8d3a08e62183786c21047189f2f08fe",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Python Rgonomics: User-defined functions in polars\"\ndescription: \"Polars provides a consistent API for conducting transformations against a DataFrame. But what do you do when you need to apply a user-defined function beyond the native API? This post surveys the patterns for transformation and aggregation with UDFs, including vector / object output, expression expansion, and when to break the abstraction with partitions and list comprehensions\"\nauthor: \"Emily Riederer\"\ndate: \"2025-11-16\"\ncategories: [rstats, python, tutorial]\nimage: \"featured.jpg\"\n---\n\n![ Photo credit to [Hans-Jurgen Mager](https://unsplash.com/@hansjurgen007) on Unsplash ](featured.jpg)\n\n`polars` API is a delight in part because of its consistency. Transformations are chained sequentially onto the DataFrame in a consistent series of steps without leaving the DataFrame. This helps developers get \"in the flow\", produces highly readable and well-structured code, and cna make a very natural transition for users coming from R's `tidyverse` who tend to think about data tranformations in a series of \"pipes\".\n\nWhile the API has excellent coverage over a wide range of standard transformations that data practitioners need^[Beyond `dplyr`, analogous to much of what an R user might find in `stringr`, `lubridate`, `tidyr`, among others], users may often find the need to incorporate user-defined functions (UDFs) into their logic to leverage other python libraries for domain-specific problems. This can arise frequently in data science where models more germane to modeling and statistical testing are, by design, not built separately into polars. \n\nThis creates multiple points of potential friction:\n\n- `polars` is highly readable due to the API's consistent use of method chaining; applying UDFs shouldn't break the flow\n- users may wish to return more complex \"non-scalar\" datatypes (e.g. multidimensional arrays, model objects) into the DataFrame^[This is a non-uncommon pattern with R `tidyverse`'s list columns]\n\nThis post is a quick reference to demonstrate `polars`' numerous capabilities for integrating different types of external (from other packages) or custom (user modularized) logic without breaking the flow of `polars` transformations. Using examples from data simulation, model evlauation, and inference, we will explore methods for applying UDFs for transformation and aggregation, transforming complex objects within a `polars` pipe, and easy \"escape hatches\" to break the abstraction when necessary. \n\n## TLDR\n\nWhenever possible, it is most efficient to express your custom user-defined function (UDF) in the native `polars` API. When the API affords the logic you need to do this, you can modularize that `polars` code into a function that takes an expression or a DataFrame as it's first argument and add it to your `polars` code with: \n\n- `pipe()` -- allows piping of expressions and DataFrames into UDFs\n- `map_columns()` -- custom pipe function capable of handling contexts like selectors\n\nFor arbitrary python logic to transform expressions (i.e. at the column-level), you can use `map_{batches|elemens()}` within `with_columns()`:\n\n- `map_batches()` -- for applying non-polars vectorized functions (preferred)\n- `map_elements()` -- for applying nonvectorized functions (less efficient)\n\nSimilarly, for arbitrary expression aggregation, `map_groups()` can be used inside of `agg()`:\n\n- `map_groups()` -- to keep everything in the DataFrame\n\nHowever, there are numerour hacks and special cases to make your code either more efficient or more readable:\n\n- `polars` extensions may provide a more native Rust implementation of the logic\n- creating a generation function can mimic `polars`'s [expression expansion](https://docs.pola.rs/user-guide/expressions/expression-expansion/), allowing you to apply the same transformation to many columns at once\n- the ability to `map_*()` objects with return type `pl.Object` means you can fit any number of complex objects (e.g. models) into a `polars` pipeline that you wish to keep wrangling\n- `partition_by()` provides an easy off-ramp for breaking out of the DataFrame abstraction for further processing with comfortable python-native patterns like list comprehensions\n\n## Set Up\n\nWe'll load a few packages to begin:\n\n::: {#17172b6d .cell execution_count=1}\n``` {.python .cell-code}\nimport polars as pl\nimport polars.selectors as cs\nimport polars_ds as pds\nimport numpy as np\nfrom numpy.random import binomial\nfrom sklearn.metrics import roc_auc_score\nimport statsmodels.api as sm\n```\n:::\n\n\n## Applying `polars` UDFs\n\nNow, imagine you simply want to be able to apply and reuse a user-defined function (UDF) writeen with native `polars` logic. This is easily done with the `pipe()` method which can be chained onto either expressions (logic that computes variables in the DataFrame) or full DataFrames. Writing additional transformation logic with the native python API is preferable wherever it is possible since it allows `polars` to use the same data representations and optimizations. \n\nWe'll start with a boring toy dataset.\n\n::: {#22718b73 .cell execution_count=2}\n``` {.python .cell-code}\ndata_dict = {\n  'group': ['a']*4 + ['b']*4,\n  'x': np.arange(1,9,1),\n  'y': np.arange(8,0,-1), \n  'p': np.arange(1,9,1)/10\n}\ndf = pl.DataFrame(data_dict)\ndf.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 8\nColumns: 4\n$ group <str> 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'\n$ x     <i64> 1, 2, 3, 4, 5, 6, 7, 8\n$ y     <i64> 8, 7, 6, 5, 4, 3, 2, 1\n$ p     <f64> 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8\n\n```\n:::\n:::\n\n\n### Columns (`pipe` and `map_columns()`)\n\n::: {#a5616b63 .cell execution_count=3}\n``` {.python .cell-code}\ndef cap(c:pl.Expr, ceil:int = 5) -> pl.Expr: return pl.when( c > ceil).then(ceil).otherwise( c )\n\ndf.with_columns( pl.col('x').pipe(cap))\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>literal</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>1</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>2</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>3</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>4</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>5</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>5</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>5</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>5</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThis is also works when applying a transformation to mutliple columns with selectors. However, the pipe can result in a conflict in which all variables have the same name (unlike native chaining). This is fixed by appending `.name.keep()` which access and reapplies the name of the initial column being mapped. \n\n::: {#3914292c .cell execution_count=4}\n``` {.python .cell-code}\ndf.with_columns( cs.numeric().pipe(cap).name.keep() )\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>5</td><td>0.1</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>5</td><td>0.2</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>5</td><td>0.3</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>3</td><td>0.6</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>2</td><td>0.7</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>1</td><td>0.8</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIf you have no other transformations you wish to do simultaneously, `map_columns()` is a slightly more concise alternative which accepts a column selector and a single transformation to be applied to all passed columns. \n\n::: {#55b75d0a .cell execution_count=5}\n``` {.python .cell-code}\ndf.map_columns( cs.numeric(), cap)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>5</td><td>0.1</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>5</td><td>0.2</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>5</td><td>0.3</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>3</td><td>0.6</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>2</td><td>0.7</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>1</td><td>0.8</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Data Frames (`pipe`)\n\nAlternatively, you may wish to encapsulate logic operating at the level of the entire DataFrame versus an individual column.\n\n::: {#ba63d47c .cell execution_count=6}\n``` {.python .cell-code}\ndef calc_diffs(df:pl.DataFrame, threshhold:int = 5) -> pl.DataFrame:\n\n    df_out = (\n        df\n        .with_columns(\n            abs = (pl.col('x') - pl.col('y')).abs(),\n            abs_gt_t = (pl.col('x') - pl.col('y')).abs() > threshhold,\n        )\n    )\n    return df_out \n```\n:::\n\n\nThis too can be chained onto a DataFrame using the `pipe()`:\n\n::: {#ece13d41 .cell execution_count=7}\n``` {.python .cell-code}\ndf.pipe(calc_diffs)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>abs</th><th>abs_gt_t</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>7</td><td>true</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>5</td><td>false</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>3</td><td>false</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>3</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>5</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>7</td><td>true</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nValues of other arguments to your function can be passed with kwargs^[That is, passed as a named argument to `pipe` which will, in turn, pass it to the internal function being piped.]\n\n::: {#537f1f9c .cell execution_count=8}\n``` {.python .cell-code}\ndf.pipe(calc_diffs, threshhold = 3)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>abs</th><th>abs_gt_t</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>7</td><td>true</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>5</td><td>true</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>3</td><td>false</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>3</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>5</td><td>true</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>7</td><td>true</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThis also allows us to write DataFrame-level functions that operate on different variables by passing the variables as parameters.\n\n::: {#1559718d .cell execution_count=9}\n``` {.python .cell-code}\ndef calc_diffs(df:pl.DataFrame, var1:str = 'x', var2:str = 'y', threshhold:int = 5) -> pl.DataFrame:\n\n    df_out = (\n        df\n        .with_columns(\n            abs = (pl.col(var1) - pl.col(var2)).abs(),\n            abs_gt_t = (pl.col(var1) - pl.col(var2)).abs() > threshhold,\n        )\n    )\n    return df_out \n\ndf.pipe(calc_diffs, var1 = 'y', var2 = 'x', threshhold = 3)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>abs</th><th>abs_gt_t</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>7</td><td>true</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>5</td><td>true</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>3</td><td>false</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>1</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>3</td><td>false</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>5</td><td>true</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>7</td><td>true</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Applying custom series transformations\n\nPiping is great, but it can break down when you need to apply column transformations requiring multiple columns as inputs or requiring logic outside of the `polars` API. That's where `map_batches()` and `map_elements()` become useful. \n\nThese methods chain onto expressions just like other transformations. However, they can accept as arguments any arbitrary python function, as well as specifications for the type of return (scalar or vector, data types). The two methods differ in that `map_batches()` expects the function to be vectorized whereas `map_elements()` can use any arbitrary function (but assumes it will have to iterate over inputs). \n\nWith these methods, we can input one or more expressions from a DataFrame and return either a scalar or a vector output. \n\n### Map Batches \n\nImagine we want to simulate draws from a binomial distribution, based on the sample size `x` and probability `p` in the dataset above. \n\nIn the simplest case in which our function receives 1 input, we can chain `map_batches()` onto that expression. Here, we simply provide the function of interest and option fields to confirm that our return value is a scalar (the result of a single coin flip) of type integer:\n\n::: {#8037089b .cell execution_count=10}\n``` {.python .cell-code}\n# one column in, one value out\ndf.with_columns(\n    coin_flip = pl.col('p').map_batches(function = lambda p: binomial(n = 1, p = p), returns_scalar = True, return_dtype = pl.UInt16)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>coin_flip</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>u16</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>0</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>0</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>1</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>0</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>1</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>0</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>1</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>1</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nHowever, if our function requires multiple expressions as inputs, we must either create a `struct` or internally pass the names of those expressions to `exprs` (which I find cleaner). The function you are mapping must similar assume it is receiving an input containing those expressions in the same order and, thus, accessing them through indexing.\n\n::: {#1567a6cf .cell execution_count=11}\n``` {.python .cell-code}\n# two column in, one value out - with structs\ndf.with_columns(\n    coin_flip = pl.struct('x','p').map_batches(\n                               function = lambda z: binomial(n = z.struct['x'], p = z.struct['p']), \n                               returns_scalar = True, return_dtype = pl.UInt16)\n)\n\n# two columns in, one value out - with exprs\ndf.with_columns(\n    coin_flip = pl.map_batches(exprs = ['x', 'p'],\n                               function = lambda z: binomial(n = z[0], p = z[1]), \n                               returns_scalar = True, return_dtype = pl.UInt16)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>coin_flip</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>u16</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>0</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>0</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>0</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>0</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>4</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>4</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>5</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>7</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Multiple Outputs\n\nFinally, you can also return multiple outputs. Suppose we want to simulate 100 draws not just 1. Our internal function can instead return an array. Afterward, we can calculate the average outcome versus the expected value to see that this worked as intended. \n\n::: {#b0b11d90 .cell execution_count=12}\n``` {.python .cell-code}\n# many columns out\ndf.with_columns(\n    coin_flip = pl.struct('x','p').map_batches(\n                               function = lambda z: binomial(n = z.struct['x'], \n                                                             p = z.struct['p'],\n                                                             size = (100,z.shape[0])\n                                                             ).transpose(), \n                                return_dtype = pl.Array(pl.UInt16, 100) \n                                )\n).with_columns( \n    avg_outcome = pl.col('coin_flip').arr.mean(),\n    exp_value = pl.col('x') * pl.col('p')\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>x</th><th>y</th><th>p</th><th>coin_flip</th><th>avg_outcome</th><th>exp_value</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>array[u16, 100]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>8</td><td>0.1</td><td>[0, 0, … 0]</td><td>0.08</td><td>0.1</td></tr><tr><td>&quot;a&quot;</td><td>2</td><td>7</td><td>0.2</td><td>[0, 0, … 1]</td><td>0.4</td><td>0.4</td></tr><tr><td>&quot;a&quot;</td><td>3</td><td>6</td><td>0.3</td><td>[1, 2, … 1]</td><td>0.94</td><td>0.9</td></tr><tr><td>&quot;a&quot;</td><td>4</td><td>5</td><td>0.4</td><td>[2, 2, … 3]</td><td>1.67</td><td>1.6</td></tr><tr><td>&quot;b&quot;</td><td>5</td><td>4</td><td>0.5</td><td>[3, 0, … 2]</td><td>2.59</td><td>2.5</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>3</td><td>0.6</td><td>[4, 4, … 4]</td><td>3.64</td><td>3.6</td></tr><tr><td>&quot;b&quot;</td><td>7</td><td>2</td><td>0.7</td><td>[5, 6, … 4]</td><td>4.69</td><td>4.9</td></tr><tr><td>&quot;b&quot;</td><td>8</td><td>1</td><td>0.8</td><td>[8, 8, … 4]</td><td>6.19</td><td>6.4</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Applying custom aggregations (Map Groups)\n\nSimilar to column transformations, `polars` can also handle arbitrary data aggregation logic with `map_groups()`. \n\nConsider a DataFrame with multiple model scores:\n\n::: {#a61ae380 .cell execution_count=13}\n``` {.python .cell-code}\ndata_dict = {\n  'group': ['a']*4 + ['b']*4,\n  'truth': [1,1,0,0]*2,\n  'mod_bad': [0.25,0.25,0.75,0.75]*2, \n  'mod_bst': [0.99,0.75,0.25,0.01]*2,\n  'mod_rnd': [0.5]*8,\n  'mod_mix': [0.99,0.75,0.25,0.01]+[0.5]*3+[0.6]\n}\ndf = pl.DataFrame(data_dict)\ndf.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 8\nColumns: 6\n$ group   <str> 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'\n$ truth   <i64> 1, 1, 0, 0, 1, 1, 0, 0\n$ mod_bad <f64> 0.25, 0.25, 0.75, 0.75, 0.25, 0.25, 0.75, 0.75\n$ mod_bst <f64> 0.99, 0.75, 0.25, 0.01, 0.99, 0.75, 0.25, 0.01\n$ mod_rnd <f64> 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5\n$ mod_mix <f64> 0.99, 0.75, 0.25, 0.01, 0.5, 0.5, 0.5, 0.6\n\n```\n:::\n:::\n\n\n`map_groups()` allows us to conduct arbitrary aggregations, such as calculating AUROC by group from the `scikit-learn` package. As you can see, the approach is largely the same: specifying the expressions required, the function used, the return type, and the return structure.\n\n::: {#6b1ad2ff .cell execution_count=14}\n``` {.python .cell-code}\ndf.group_by('group').agg (\n    pl.map_groups(\n    exprs = ['truth', 'mod_mix'],\n    function = lambda x: roc_auc_score(x[0], x[1]),\n    return_dtype = pl.Float64,\n    returns_scalar = True\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>truth</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1.0</td></tr><tr><td>&quot;b&quot;</td><td>0.25</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Alternatives & extensions \n\nOnce you understand the different mapping capabilities available with `polars`, you can use these effectively both to *expand* the paradigm or to decide when you want to *deviate* from it. We'll conclude by looking at some examples of each.\n\n### Extension libraries\n\nRecall that native Rust and `polars` implementations will generally be faster than the techniques shown. Thus, another good option is to familiarize yourself with the burgeoning ecosystem of `polars` extensions to see if one suits your needs. [Awesome Polars](https://github.com/ddotta/awesome-polars?tab=readme-ov-file#librariespackagesscripts) maintains a growing list of such packages.\n\nFor example, the `polars-ds` package can natively handle the AUROC use case above as it provides many useful evaluation functions:\n\n::: {#d7f8f982 .cell execution_count=15}\n``` {.python .cell-code}\ndf.group_by('group').agg (\n    auroc = pds.query_roc_auc('truth', 'mod_bst')\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>auroc</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1.0</td></tr><tr><td>&quot;b&quot;</td><td>1.0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### The Generator Trick\n\nWhile `pds.query_roc_auc()` can calculate AUROC out of the box, it expect string column names as inputs -- not expressions. That means we cannot benefit from `polars`'s selectors and expression expansion to calculate multiple combinations of columns with one line of code (e.g. calculation AUROC for each combination of `truth` and varying model scores). \n\nTo apply an aggregation to multiple column subsets, [the Polars docs recommend](https://docs.pola.rs/user-guide/expressions/expression-expansion/#programmatically-generating-expressions) a pattern like this: \n\n- write a wrapper function that handles the iteration and acts as a generator yielding the expression of interest \n- obtain relevant selectors to pass into the function (here, you can use the `cs.expand_selectors()` helpers or any raw parsing of the column names)\n- pass the generator into the standard `df.group_by(...).agg(...)` flow\n\n::: {#bce5eb37 .cell execution_count=16}\n``` {.python .cell-code}\ndef auroc_expressions(models):\n    for m in models:\n        yield pds.query_roc_auc( 'truth', m).alias(m)\n\nmods = cs.expand_selector(df, cs.starts_with('mod_')) # could also do: [c for c in df.columns if c[:4] == 'mod_']\ndf.group_by('group').agg( auroc_expressions( mods ))\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>mod_bad</th><th>mod_bst</th><th>mod_rnd</th><th>mod_mix</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>-0.0</td><td>1.0</td><td>0.5</td><td>1.0</td></tr><tr><td>&quot;b&quot;</td><td>-0.0</td><td>1.0</td><td>0.5</td><td>0.25</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Complex Object Types \n\n`polars` DataFrames can hold arbitrary objects (of datatype `pl.Object`) -- not just scalars and vectors. This means, if we so choose, we can do complex multi-step tasks without leaving the DataFrame^[This mirrors patterns from `tidymodel`, `dplyr`, and `purrr` in R.]\n\nConsider one final sample dataset:\n\n::: {#fb1c9f6d .cell execution_count=17}\n``` {.python .cell-code}\ndata_dict = {\n  'group': ['a']*4 + ['b']*4,\n  'x': [0.99,0.75,0.25,0.01]*2,\n  'y': [0.99,0.75,0.25,0.01]+[0.5]*3+[0.6]\n}\ndf = pl.DataFrame(data_dict)\ndf.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 8\nColumns: 3\n$ group <str> 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'\n$ x     <f64> 0.99, 0.75, 0.25, 0.01, 0.99, 0.75, 0.25, 0.01\n$ y     <f64> 0.99, 0.75, 0.25, 0.01, 0.5, 0.5, 0.5, 0.6\n\n```\n:::\n:::\n\n\nIf we wish, we can even use `map_groups()` to create a column that represents complex objects like *models* and then `map_elements()` to extract information from these models. \n\n::: {#c6b112c7 .cell execution_count=18}\n``` {.python .cell-code}\n(\ndf.group_by('group').agg (\n    mod = pl.map_groups(\n    exprs = ['x', 'y'],\n    function = lambda x: sm.OLS( x[0].to_numpy(), sm.add_constant( x[1] )).fit() ,\n    return_dtype = pl.Object,\n    returns_scalar = True\n    )\n)\n.with_columns(\n    params = pl.col('mod').map_elements(lambda x: x.params, return_dtype = pl.List(pl.Float64)),\n    r_sq  = pl.col('mod').map_elements(lambda x: x.rsquared, return_dtype = pl.Float64)\n)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>group</th><th>mod</th><th>params</th><th>r_sq</th></tr><tr><td>str</td><td>object</td><td>list[f64]</td><td>f64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x0000020F4EEC4A10&gt;</td><td>[-1.7347e-16, 1.0]</td><td>1.0</td></tr><tr><td>&quot;b&quot;</td><td>&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x0000020F01A0B550&gt;</td><td>[3.93, -6.533333]</td><td>0.528971</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThis pattern can be very useful if you are doing something like, for example, bootstrap aggregation. It might not be the most efficient computationally (not parallelized), but for small problems where speed is not a gamechanger, it can make for concise and readable analysis. \n\n### Partitions \n\nHowever, just because you *can* keep everything in a DataFrame does not mean you should. The above pattern is useful if your end goal is to extract a singular quantity like a coefficient back into the DataFrame. However, if you ultimately want to go do other things with the objects you are generating, it may make for cleaner code to go ahead and break the DataFrame abstraction. \n\nA final pattern I find particularly pleasant and effective is using the `partition_by()` method. This splits a DataFrame into separate frames based on grouping columns and organizes them in either a list (by default) or as a dictionary (when `as_dict = True`) indexed with a tuple containing the values of the grouping variable(s). \n\n::: {#5ded18ca .cell execution_count=19}\n``` {.python .cell-code}\ndfs = df.partition_by('group', as_dict = True, include_key = True)\nfor k,v in dfs.items():\n    print(f\"{k}  : {v}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n('a',)  : shape: (4, 3)\n┌───────┬──────┬──────┐\n│ group ┆ x    ┆ y    │\n│ ---   ┆ ---  ┆ ---  │\n│ str   ┆ f64  ┆ f64  │\n╞═══════╪══════╪══════╡\n│ a     ┆ 0.99 ┆ 0.99 │\n│ a     ┆ 0.75 ┆ 0.75 │\n│ a     ┆ 0.25 ┆ 0.25 │\n│ a     ┆ 0.01 ┆ 0.01 │\n└───────┴──────┴──────┘\n('b',)  : shape: (4, 3)\n┌───────┬──────┬─────┐\n│ group ┆ x    ┆ y   │\n│ ---   ┆ ---  ┆ --- │\n│ str   ┆ f64  ┆ f64 │\n╞═══════╪══════╪═════╡\n│ b     ┆ 0.99 ┆ 0.5 │\n│ b     ┆ 0.75 ┆ 0.5 │\n│ b     ┆ 0.25 ┆ 0.5 │\n│ b     ┆ 0.01 ┆ 0.6 │\n└───────┴──────┴─────┘\n```\n:::\n:::\n\n\nThis allows up to break up the data in the way we wish to process it, and then do processing in more python-native syntax such as a list comprehension. I find this makes highly concise and readable code and is ultimately a better strategy when further data wrangling is not needed. \n\n::: {#c998e7d4 .cell execution_count=20}\n``` {.python .cell-code}\ndfs = df.partition_by('group', as_dict = True, include_key = True)\ngrps = [ k[0] for k in dfs.keys() ] # turn tuple to scalar bcs only one grouping var in key\nmods = [ sm.OLS( d['x'].to_numpy(), \n                 sm.add_constant( d['y'].to_numpy() )\n                ).fit() for k,d in dfs.items()]\ncoef = [m.params[1] for m in mods]\ndict(zip( grps, coef))\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n{'a': np.float64(1.0000000000000004), 'b': np.float64(-6.533333333333337)}\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}