<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Emily Riederer</title>
<link>https://emilyriederer.com/#category=data</link>
<atom:link href="https://emilyriederer.com/index-data.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.554</generator>
<lastBuildDate>Sat, 16 Aug 2025 05:00:00 GMT</lastBuildDate>
<item>
  <title>MLOrbs?: MLOps in the database with orbital and dbt</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/orbital-mlops/</link>
  <description><![CDATA[ 





<p>So, you build a great predictive model. <em>Now what</em>?</p>
<p><a href="https://mlops.community/">MLOps</a> is hard. Deploying a model involves different tools, skills, and risks than model development. This dooms some data science projects to die on their creator’s hard drive.</p>
<p>Tools like <code>dbt</code> and <code>SQLMesh</code> entered the scene to solve a similar problem for data analysts. These tools offer an opinionatee frameowrk for organizing multiple related SQL scripts into fully tested, orchestrated, and version conotrolled projects. Data analysts can deliver end-to-end pipelines by applying their existing business context, SQL experience, and database modeling<sup>1</sup> acumen into existing infrastructure, resulting in the rise of “analytics engineering”.</p>
<p>So what is the <code>dbt</code> for data scientists doing MLOps? It turns out, it <em>might</em> just be… <code>dbt</code>! (Enter caveats galore).</p>
<p>Posit’s <a href="https://posit.co/blog/introducing-orbital-for-scikit-learn-pipelines/">recently announced</a> <code>orbital</code> project<sup>2</sup> translates feature enginering and model scoring code training in <code>scikit-learn</code> pipelines (python) and <code>tidymodels</code> workflows into raw SQL code. Similar to <code>dbt</code>, this has the potential to help data scientist’s deploy their own models batch scoring models using existing tools (R, python, SQL) an infrastructure (analytical database) by creating a new table or view in their data warehouse (or pointing <code>duckdb</code> against their data lake!) Coupled with <code>dbt</code>, the combination unlocks baseline “good enough” MLOps practices at no-to-low cost and zero additional infrastructure.</p>
<p>In this post, I explore a workflow for using <code>orbital</code> and <code>dbt</code> for zero-infrastructure deployment of batch models inside of a <code>dbt</code> pipeline. We’ll discuss:</p>
<ul>
<li>what makes MLOps hard</li>
<li>when database/<code>dbt</code>-based deployment might help</li>
<li>a reference implementation and workflow for <code>dbt</code> + <code>orbital</code><sup>3</sup></li>
<li>how preexisting <code>dbt</code> + <code>orbital</code> features address common MLOps pain points</li>
<li>limitations and caveats to the above approach</li>
</ul>
<p>Along the way, we’ll walk through this <a href="https://github.com/emilyriederer/orbital-exploration/tree/main/dbt_orb_demo">demo implementation of a churn prediction model</a> (wow, what a cliche). The demo is fully self-contained with open data and a <code>duckdb</code> backend if you want to pull it down and play along!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R and python compatibility
</div>
</div>
<div class="callout-body-container callout-body">
<p>My example in this post uses the <code>orbital</code> python package to translate a <code>scikit-learn</code> pipline to SQL. However, there is also an <code>orbital</code> R package that can translate <code>tidymodels</code>. This post is more about the <em>workflow</em> of preparing and consuming <code>orbital</code> output in <code>dbt</code>, so it’s mostly useful for either language.</p>
</div>
</div>
<section id="mlops-challenges" class="level2">
<h2 class="anchored" data-anchor-id="mlops-challenges">MLOps Challenges</h2>
<p>Predictive modeling requires nuanced, detailed thinking; MLOps requires systems thinking. Success requires an unlikely combination of skills including a deep understanding of the business problem, the modeling workflow, and engineering principles. Some key challenges include:<sup>4</sup></p>
<ul>
<li>Data management &amp; testing
<ul>
<li>Pre-modeling (not exactly MLOps) – test source data upstream of the initial query for better visibility into quality errors or concept drift</li>
<li>Scoring time – preventing scoring on features ranges not seen in training when this poses inordinate risk</li>
</ul></li>
<li>Recreating the development / evaluation environment
<ul>
<li>Feature transformations – ensuring feature availability in prod (no leakage!) and same transformation logic as dev</li>
<li>Environment management – controling package versions and dependencies for scoring code</li>
<li>Versioning – tracking changes to the model over time</li>
</ul></li>
<li>Serving relevance
<ul>
<li>Access – controlling access to intended consumers and delivering to platform they can use</li>
<li>Reliability – ensuring predictions are retrievable on-demand</li>
</ul></li>
<li>Reproducibility / Observability
<ul>
<li>Snapshotting – ability to store past predictions for auditability and performance monitoring</li>
<li>Testing – inserting tests at relevant points in the pipeline, providing observability and automated error handling</li>
<li>Logging – ensuring general system observability of performance, errors, retries, and latency</li>
</ul></li>
</ul>
<p>These technical challenges are exacerbated by cultural factors. In small companies, data teams may be small (or even a data team-of-one) and lack bandwidth for model deployment, engineering-focused skillsets, access to enterprise-grade tools, or stakeholders who would know how to consume model predictions published in bespoke environments. In large companies, modelers may not be allowed access to production systems required for deployment, so handoffs often require prioritization and context sharing across multiple teams.</p>
</section>
<section id="deploying-to-the-database" class="level2">
<h2 class="anchored" data-anchor-id="deploying-to-the-database">Deploying to the database</h2>
<p>For the right use cases, publishing predictions back into an analytical warehouse can be an attractive proposition. This approach is best suited for offline batch scoring, such as models that:</p>
<ul>
<li>drive bulk actions in downstrean CRMs, e.g.&nbsp;marketing segments to drive targeted emails<sup>5</sup></li>
<li>inform human decision-making, e.g.&nbsp;individual predictions that rollup into quarterly sales forecast dashboard</li>
<li>are reincorporated in downstream analysis similar to raw data, e.g.&nbsp;model validation and backtesting, publish a set of propensity scores back into a clinical database</li>
</ul>
<p>In such cases, there are many advantages of having model predictions in the database:</p>
<ul>
<li><strong>Fast &amp; accurate deployment</strong>: SQL-based deployment means you can deploy your data against exactly the same data is was trained on, reducing the risk of feature drift between dev and prod. Similarly, it reduced ongoing headaches of dependency management since SQL is generally a stable language<sup>6</sup> and does not depend on external packages.</li>
<li><strong>Data management tools</strong>: Features, scores – at the end of the day <em>its all just data flow</em>. Having predictions in the database unlocks the ability to leverage on other features integrated in your database like access controls, data quality checks, scheduled updates, incremental loads, and snapshots.</li>
<li><strong>Integration</strong>: Many modern data stacks have their analytical data warehouse connected to many other business-critical systems like dashboards and CRMs (e.g.&nbsp;MailChimp) or are easy to integrate via numerous reverse ETL solutions. Serving predictions to a warehouse is a great first step to syncing them <em>beyond</em> the warehouse in the platforms where they can drive actions like customer contacts.</li>
<li><strong>Development language agnosticism</strong>: For R users tired of the “we don’t put R in production” conversations, SQL provides a generic abstraction layer to “hand off” a model object regardless of how it was developed</li>
</ul>
<p>Conversely, this solution is poorly suited for real-time models where models are scored for single observations on the fly. I share a few more thoughts on when this solution is not well-suited in the final section of this post, Section&nbsp;4.</p>
</section>
<section id="orbital-dbt-pattern" class="level2">
<h2 class="anchored" data-anchor-id="orbital-dbt-pattern"><code>orbital</code> + <code>dbt</code> Pattern</h2>
<p>To demonstrate how an <code>orbital</code> + <code>dbt</code> pattern could work, I’ll walk through <a href="https://github.com/emilyriederer/orbital-exploration/tree/main/dbt_orb_demo">this example project</a>, using <a href="https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/data/Telco-Customer-Churn.csv">IBM’s telcom churn dataset</a>. The project mostly is mostly structured like a standard <code>dbt</code> project with most of the model training and <code>orbital</code> code in <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/model_dev/train_and_convert.ipynb">this additional notebook</a>.</p>
<p>Churn prediction might be a good candidate for batch scoring. Each month, accounts reaching their resubscription date could be scored and published to a database. Scores might then be used analytical use cases like monitoring or revenue forecasting and operational use cases like ingesting segments into a CRM to email targeted retention offers.</p>
<p>We’ll work up to this final pipeline:</p>
<p><img src="https://emilyriederer.com/post/orbital-mlops/full.png" class="img-fluid"></p>
<p>The point of this exercise is to think about the <code>orbital</code> and <code>dbt</code> architecture, so the model we deploy will be quite uninventive. Pull down some features, one-hot encode, fit a random forest, and do it all in a (<em>gasp</em>) Jupyter notebook. (Please dont’ do this.)</p>
<section id="sec-design" class="level3">
<h3 class="anchored" data-anchor-id="sec-design">Key Features and Design Choices</h3>
<p>If you want the TLDR, I’ll briefly explain the key design choices for this pipeline:</p>
<ul>
<li>Initial Data Preparation
<ul>
<li>Set up <code>dbt test</code>s to test sources before joining your feature table. This can better catch dropout from failed joins, newly emerging encoded categories, etc. Consider what additional filters you want to put in downstream tables (Better to “alert and allow” and “block until fixed”?)</li>
<li>Prepare feature separately (for normalization) but join different features in database to take advantage of database processing</li>
<li>Consider adding random number in training table for reproducible test/train split (this has to be linked to hash or something about the entities your randomizing to ensure reproducibility without regard to ordering of data samples)</li>
</ul></li>
<li>Feature Engineering
<ul>
<li>Create separate <code>scikit-learn</code> pipelines and/or <code>tidymodels</code> workflows for the feature engineering and training steps so you can render these as separate queries. This can enable better data testing and make queries more efficient so <code>orbital</code> does not repeat the feature transformation logic</li>
<li>Use test-driven development to update <code>dbt</code> data tests as you develop. For example, encoding a categorical? Immediately add an upstream test to check for previously unseen values.</li>
</ul></li>
<li>Preparing <code>orbital</code> SQL (supported by <code>sqlglot</code>)
<ul>
<li>Add back your identifier column to the query so predictions are joinable</li>
<li>Add a model version field into the query for better context to users</li>
<li>Change placeholder table to a <code>dbt</code> <code>ref()</code></li>
<li>Rename columns to remove <code>.</code>s so you do not have to always quote in queries</li>
<li>Output nicely formatted version for readability</li>
</ul></li>
<li>Deploying as a model
<ul>
<li>Consider carefully whether to make a table, view, or macro depending on your specific database, query latency, and desire to score bespoke populations</li>
</ul></li>
<li>Observability, logging, and error handling
<ul>
<li>Use <code>dbt snapshots</code> to save timestamped past predictions and feature values if these can change over time. This improves auditability and future analysis</li>
<li>Execute tests to <code>--store-failures</code> to detect changes in your data that might require model retraining or additional error handling</li>
<li>Check out <code>dbt</code> packages like <a href="https://hub.getdbt.com/elementary-data/elementary/latest/">elementary</a> to log more aspects of the model run process</li>
</ul></li>
</ul>
</section>
<section id="set-up" class="level3">
<h3 class="anchored" data-anchor-id="set-up">Set-Up</h3>
<p>The sample IBM data is provided as “one big table”, so I <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/setup/prep-seeds.py">break things up</a> to look a bit more like normalized database data representing subscription information, billing information, demographics, and churn targets. I also add a few columns to simulate different months, censor data I want to pretend is in the future, and add a few data errors for fun.</p>
<p>Here’s a preview of the resulting tables, connected by a <code>customer_id</code> primary key:</p>
<div id="ace4cd8c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dev.duckdb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> con:</span>
<span id="cb1-5"></span>
<span id="cb1-6">    df_serv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'serv'</span>).pl()</span>
<span id="cb1-7">    df_bill <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bill'</span>).pl()</span>
<span id="cb1-8">    df_demo <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'demo'</span>).pl()</span>
<span id="cb1-9">    df_chrn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'chrn'</span>).pl()</span></code></pre></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Services Enrolled</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Billing Information</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Demographics</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" aria-controls="tabset-1-4" aria-selected="false">Churn</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div id="018c10f8" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">df_serv.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 7043
Columns: 12
$ customer_id        &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ tenure             &lt;i32&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62
$ phone_service      &lt;str&gt; 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes'
$ multiple_lines     &lt;str&gt; 'No phone service', 'No', 'No', 'No phone service', 'No', 'Yes', 'Yes', 'No phone service', 'Yes', 'No'
$ internet_service   &lt;str&gt; 'DSL', 'DSL', 'DSL', 'DSL', 'Fiber optic', 'Fiber optic', 'Fiber optic', 'DSL', 'Fiber optic', 'DSL'
$ online_security    &lt;str&gt; 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes'
$ online_backup      &lt;str&gt; 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes'
$ device_protection  &lt;str&gt; 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No'
$ tech_support       &lt;str&gt; 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No'
$ streaming_tv       &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No'
$ streaming_movies   &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No'
$ dt_renewal        &lt;date&gt; 2025-07-01, 2025-07-01, 2025-07-01, 2025-07-01, 2025-07-01, 2025-07-01, 2025-08-01, 2025-07-01, 2025-07-01, 2025-07-01
</code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div id="c3c97fd5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">df_bill.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 7043
Columns: 6
$ customer_id       &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ contract          &lt;str&gt; 'Month-to-month', 'One year', 'Month-to-month', 'One year', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'One year'
$ paperless_billing &lt;str&gt; 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No'
$ payment_method    &lt;str&gt; 'Electronic check', 'Mailed check', 'Mailed check', 'Bank transfer (automatic)', 'Electronic check', 'Electronic check', 'Credit card (automatic)', 'Mailed check', 'Electronic check', 'Bank transfer (automatic)'
$ monthly_charges   &lt;f64&gt; 29.85, 56.95, 53.85, 42.3, 70.7, 99.65, 89.1, 29.75, 104.8, 56.15
$ total_charges     &lt;f64&gt; 29.85, 1889.5, 108.15, 1840.75, 151.65, 820.5, 1949.4, 301.9, 3046.05, 3487.95
</code></pre>
</div>
</div>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div id="795b373c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">df_demo.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 7043
Columns: 5
$ customer_id    &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ gender         &lt;str&gt; 'Female', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male'
$ senior_citizen &lt;i32&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
$ partner        &lt;str&gt; 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No'
$ dependents     &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes'
</code></pre>
</div>
</div>
</div>
<div id="tabset-1-4" class="tab-pane" aria-labelledby="tabset-1-4-tab">
<div id="d80ba20a" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">df_chrn.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 7043
Columns: 2
$ customer_id &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ churn       &lt;str&gt; 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No'
</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Ultimately, these are saved as <code>seeds</code> in the dbt project as a lightweight way to ingest small CSVs; in reality, they would be my <code>sources</code> flowing into my data warehouse from other production sources.</p>
</section>
<section id="features-training" class="level3">
<h3 class="anchored" data-anchor-id="features-training">Features &amp; Training</h3>
<p>Feature preparation and training are the heart of where <code>orbital</code> fits into our pipelines. I recommend doing these steps one-at-a-time and explain them similarly. However, since the code is closely coupled, I’ll provide it at once for reference. The combination of feature engineering and model training steps look like this:</p>
<div id="0cbc36d3" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Pipeline to orbital</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># build pipeline(s)</span></span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## feature pipeline does OneHotEncoding on all string columns (all are low/known cardinality)</span></span>
<span id="cb10-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## orbital can create some very verbose variable names (for uniqueness) so we clean those up some</span></span>
<span id="cb10-5">cols_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.select( cs.string() ).columns</span>
<span id="cb10-6">onho_enc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'oh'</span>, OneHotEncoder(sparse_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>), cols_str)</span>
<span id="cb10-7">ppl_feat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([</span>
<span id="cb10-8">  (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"encoder"</span>, ColumnTransformer([onho_enc], remainder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'passthrough'</span>))</span>
<span id="cb10-9">]).set_output(transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"polars"</span>)</span>
<span id="cb10-10">X_tran <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ppl_feat.fit_transform(X, y)</span>
<span id="cb10-11">X_tran.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [c.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span>).replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span>).replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'('</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>).replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">')'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> X_tran.columns]</span>
<span id="cb10-12"></span>
<span id="cb10-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## training pipeline fits actual random forest model</span></span>
<span id="cb10-14">ppl_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([</span>
<span id="cb10-15">  (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prep"</span>, ColumnTransformer([], remainder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'passthrough'</span>)),</span>
<span id="cb10-16">  (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pred"</span>, RandomForestClassifier(max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>))</span>
<span id="cb10-17">])</span>
<span id="cb10-18">ppl_pred.fit(X_tran, y)</span>
<span id="cb10-19"></span>
<span id="cb10-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># convert to orbital</span></span>
<span id="cb10-21"></span>
<span id="cb10-22">tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TBL_REF"</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># placeholder replaced in cleaning</span></span>
<span id="cb10-23"></span>
<span id="cb10-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## creating mapping of source data types to orbital types </span></span>
<span id="cb10-25">type_map <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb10-26">    pl.String:orbital.types.StringColumnType(),</span>
<span id="cb10-27">    pl.Int32:orbital.types.Int32ColumnType(),</span>
<span id="cb10-28">    pl.Float64:orbital.types.DoubleColumnType()</span>
<span id="cb10-29">}</span>
<span id="cb10-30">dict_feat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {e: type_map.get(t) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> e, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(X.columns, X.dtypes)}</span>
<span id="cb10-31">dict_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {e: type_map.get(t) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> e, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(X_tran.columns, X_tran.dtypes)}</span>
<span id="cb10-32"></span>
<span id="cb10-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## features</span></span>
<span id="cb10-34">orb_ppl_feat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> orbital.parse_pipeline(ppl_feat, features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dict_feat)</span>
<span id="cb10-35">sql_raw_feat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> orbital.export_sql(tbl, orb_ppl_feat, dialect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"duckdb"</span>)</span>
<span id="cb10-36"></span>
<span id="cb10-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## scoring</span></span>
<span id="cb10-38">orb_ppl_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> orbital.parse_pipeline(ppl_pred, features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dict_pred)</span>
<span id="cb10-39">sql_raw_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> orbital.export_sql(tbl, orb_ppl_pred, dialect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"duckdb"</span>)</span></code></pre></div>
</details>
</div>
<section id="features" class="level4">
<h4 class="anchored" data-anchor-id="features">Features</h4>
<p>Feature prep is the first use case for integrating <code>orbital</code> code in our <code>dbt</code> pipeline. Ultimately, we want to be sure our production features are identical to our development features. To do this, we make three design choices:</p>
<ul>
<li>Prepare raw features in the database (pre-joining) to take advantage of database-grade computational power and have preprocessing “published” to fuel different model experimentation
<ul>
<li>Adding a <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/models/churn_model/raw_feat.sql">model <code>raw_feat</code></a> to my dbt project that simply pre-joins relevant sources</li>
</ul></li>
<li>Make separate <code>scikit-learn</code> pipelines and <code>orbital</code> SQL output for feature and training steps for separate testing and faster scoring (Otherwise, <code>orbital</code>-generated SQL sometimes reproduces feature transformation logic at <em>every use</em> of the feature versus doing it once upfront. Depending one your database’s optimizer, it may or may not be smart enough to reorder this at runtime.)
<ul>
<li>In python, fit the <code>ppl_feat</code> pipeline (<a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/model_dev/train_and_convert.ipynb">cell 4</a>) which only fits the feature transformation steps</li>
<li>Retrieve the resulting SQL code from <code>orbital</code> and clean it up (discussed below)</li>
<li>Deploy it by writing the SQL back to the <code>models/</code> folder as a <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/models/churn_model/prep_feat.sql">model <code>prep_feat</code></a></li>
</ul></li>
<li>Noting the assumptions we are making about our data while engineering features and pushing those tests upstream to the source in the database
<ul>
<li>For example, one-hot encoding assumes the categories won’t change. So, since we are one-hot encoding the <code>internet_service</code> field from source, we can update our <code>schema.yml</code> file to <a href="https://github.com/emilyriederer/orbital-exploration/blob/b63cf4732cc8a440821ed96339bdb1655e9b9bb5/dbt_orb_demo/seeds/schema.yml#L33">add an <code>accepted_values</code> data test for that field</a> to warn us if our model is beginning to see data is was not prepared to handle<sup>7</sup>. Subsequent data models could, in theory, route these cases away from our scoring table and into a separate logging table for separate handling.</li>
</ul></li>
</ul>
<p>This way, we can deploy our exact features to the database separately from our final model for additional data validation. We can also run our dbt tests before consuming the results to ensure the assumptions that went into feature creation still hold.</p>
<p>Again, because we are using <code>dbt</code>, we can take advtange of related tools. Using the VS Code extension, we can examine our database’s DAG so far and see that our data test was correctly placed on the source:</p>
<p><img src="https://emilyriederer.com/post/orbital-mlops/source-test.png" class="img-fluid"></p>
</section>
<section id="training" class="level4">
<h4 class="anchored" data-anchor-id="training">Training</h4>
<p>Model training follows similarly. We create another sci-kit-learn pipline <code>ppl_pred</code> and train it (<a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/model_dev/train_and_convert.ipynb">cell 4</a>). This time, we just use the preprocessed data that was <code>fit_transform</code>ed in the prior step. Alternatively, we could re-retrieve our newly prepared features from the database.</p>
<p>In theory, this is where we’d also do a lot of model evaluation and iteration where being <em>outside</em> of the database in a joy. I don’t do this since getting a good model is not my goal.</p>
</section>
</section>
<section id="sql-cleanup" class="level3">
<h3 class="anchored" data-anchor-id="sql-cleanup">SQL Cleanup</h3>
<p>While <code>orbital</code> does a lot of heavy lifting, the SQL it produces is not perfect:</p>
<ul>
<li>It does not <code>SELECT</code> any metadata or identifier columns, rendering your predictions impossible to join to other data sources. Inserting this column requires care because sometimes the upstream data is being queried within the main query and other times it is queried in a CTE</li>
<li>Its hard to get <code>orbital</code> to query from a <code>ref()</code> that plays nice with <code>dbt</code>’s Jinja because <code>orbital</code> is rigorous about quoting table and column names. So, it’s easier to put a placeholder table name and edit it in post-processing.</li>
<li>It uses somewhat long and bulky variable names that reflect <code>scikit-learn</code> internals, including <code>.</code>s in column names which can reduce readability and requires quoting since <code>.</code> usually means something different in SQL</li>
<li>It includes positive predictions, negative predictions, and labels which may be excessive. I’ve never wanted anything more than the positive predictions</li>
<li>It’s not formatted which shouldn’t matter but will wrankle anyone who has ever worked with SQL</li>
</ul>
<p>To mitigate these multiple issues, <code>sqlglot</code> makes it easy to further parse the query. <code>sqlglot</code> is a package that allows you to turn any SQL script into an AST for ease of programatic modification. I defined a <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/model_dev/clean_sql.py">helper function</a> with <code>sqlglot</code> to fix all of the above.</p>
<div id="48c78f73" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Cleaning function definition</summary>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sqlglot</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sqlglot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> parse_one, exp </span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> clean_sql(sql_raw: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, </span>
<span id="cb11-5">              tbl_ref: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, </span>
<span id="cb11-6">              model_version: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb11-7">              col_id: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>, </span>
<span id="cb11-8">              cols_renm: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'output_probability.1'</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred'</span>, </span>
<span id="cb11-9">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'output_probability.0'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>, </span>
<span id="cb11-10">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'output_label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>},</span>
<span id="cb11-11">              ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb11-12"></span>
<span id="cb11-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Opinionated clean-up of SQL returned by orbital</span></span>
<span id="cb11-14"></span>
<span id="cb11-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function executes the following transformations:</span></span>
<span id="cb11-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Rename desired columns such as the prediction column (per result of cols_renm)</span></span>
<span id="cb11-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Remove unwanted variables (those being "renamed" to "0")</span></span>
<span id="cb11-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Add back ID variable for joining predictions to other datasets </span></span>
<span id="cb11-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Fix table reference from default TBL_REF to a specific dbt model reference</span></span>
<span id="cb11-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Reformats SQL for improved readability</span></span>
<span id="cb11-21"></span>
<span id="cb11-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters</span></span>
<span id="cb11-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    ----------</span></span>
<span id="cb11-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    sql_raw: SQL string provided by `orbital`</span></span>
<span id="cb11-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    tbl_ref: Name of dbt model to be referenced in query's FROM clause</span></span>
<span id="cb11-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    model_version: Version number of model to be added as own column. Defaults to None to add no column</span></span>
<span id="cb11-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    col_id: Name of the column representing the unique identifier of entities to be predicted</span></span>
<span id="cb11-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    cols_renm: Dictionary of {default_name: desired_name} to rename fields</span></span>
<span id="cb11-29"></span>
<span id="cb11-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns</span></span>
<span id="cb11-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    -------</span></span>
<span id="cb11-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    str</span></span>
<span id="cb11-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        A formatted and updated SQL query</span></span>
<span id="cb11-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb11-35"></span>
<span id="cb11-36"></span>
<span id="cb11-37">    ast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_one(sql_raw)</span>
<span id="cb11-38">    </span>
<span id="cb11-39">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> e <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> ast.expressions:</span>
<span id="cb11-40">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># rename prediction column</span></span>
<span id="cb11-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> cols_renm.get(e.alias) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0'</span>:</span>
<span id="cb11-42">            e.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(arg_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'this'</span>,value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb11-43">            e.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(arg_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'alias'</span>,value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb11-44">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> e.alias <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> cols_renm.keys():</span>
<span id="cb11-45">            e.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(arg_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'alias'</span>,value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cols_renm.get(e.alias))</span>
<span id="cb11-46">    </span>
<span id="cb11-47">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add back a variable for reference (typically like an ID for joining to other tables)</span></span>
<span id="cb11-48">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># this is tricky because sometimes orbital uses CTEs and other times it doesn't;</span></span>
<span id="cb11-49">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># generally, we need to get the identifier inside the CTE if it exists</span></span>
<span id="cb11-50">    col <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> exp.Column(this<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>exp.to_identifier(col_id))</span>
<span id="cb11-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> ast.find(exp.CTE) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb11-52">        cte_select <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ast.find(exp.CTE).this</span>
<span id="cb11-53">        cte_select.expressions.append(col)</span>
<span id="cb11-54">    ast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ast.select(col_id)</span>
<span id="cb11-55"></span>
<span id="cb11-56">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add model version to outer query if desired</span></span>
<span id="cb11-57">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> model_version <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb11-58"></span>
<span id="cb11-59">        col_version <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> exp.Alias(</span>
<span id="cb11-60">            this<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>exp.Literal.string(model_version), </span>
<span id="cb11-61">            alias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model_version"</span>)</span>
<span id="cb11-62">        ast.find(exp.Select).expressions.append(col_version)</span>
<span id="cb11-63">    </span>
<span id="cb11-64">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pretty print</span></span>
<span id="cb11-65">    sql_fmt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sqlglot.transpile(ast.sql(), </span>
<span id="cb11-66">                                write<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"duckdb"</span>, </span>
<span id="cb11-67">                                identify<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, </span>
<span id="cb11-68">                                pretty<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb11-69">    </span>
<span id="cb11-70">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># change out table to dbt reference</span></span>
<span id="cb11-71">    ref_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">{{{{</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> ref('</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tbl_ref<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">')</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">}}}}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb11-72">    sql_fnl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sql_fmt.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'"TBL_REF"'</span>, ref_str) </span>
<span id="cb11-73">  </span>
<span id="cb11-74">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> sql_fnl</span></code></pre></div>
</details>
</div>
<p>I run the SQL generated from both <code>ppl_feat</code> and <code>ppl_rafo</code> through this function before writing them to <code>models/churn_model/prep_feat.sql</code> and <code>models/churn_model/pred_churn.sql</code> in my <a href="https://github.com/emilyriederer/orbital-exploration/tree/main/dbt_orb_demo/models/churn_model"><code>dbt</code> <code>models/</code> directory</a>.</p>
<p>This establishes our core model deployment pipeline:</p>
<p><img src="https://emilyriederer.com/post/orbital-mlops/core-pipe.png" class="img-fluid"></p>
</section>
<section id="scoring-preserving-and-activating-predictions" class="level3">
<h3 class="anchored" data-anchor-id="scoring-preserving-and-activating-predictions">Scoring, Preserving, and Activating Predictions</h3>
<p>We now have a table in our database that has our churn model predictions! Here is where we can begin to utilize the full benefit of the data management tools that <code>dbt</code> has built in.</p>
<p>Before scoring, we can run our <code>dbt test</code> to ensure that our features are stable and valid.</p>
<p>For scoring, depending on our use case we can set the table materialization to be a table (rebuilt on a schedule) or a view (generated on the fly for a specific population).</p>
<p>For archiving past scores, we can update our <a href="https://github.com/emilyriederer/orbital-exploration/blob/b63cf4732cc8a440821ed96339bdb1655e9b9bb5/dbt_orb_demo/dbt_project.yml#L35">dbt-project.yml to include snapshotting</a> our predictions table. This means even if we publish our tables as a view, we could schedule a call to <code>dbt snapshot</code> on a regular basis to record a timestamped record of what our scores were at any given point in time. This could be useful for model monitoring or auditiability. For example, if we are using our churn model to segment a marketing campaign, we might need these scores later to determine who got what treatment in the campaign.</p>
<p>For staging analysis, we can use <code>dbt</code> <code>analyses</code> to <a href="https://github.com/emilyriederer/orbital-exploration/blob/main/dbt_orb_demo/analyses/churn_model_perf.sql">render the scripts</a> that might be needed to conduct model monitoring (e.g.&nbsp;merging past scores with observed targets.)</p>
<p>We can see examples of these different artifacts branching off of our DAG:</p>
<p><img src="https://emilyriederer.com/post/orbital-mlops/artifacts.png" class="img-fluid"></p>
</section>
<section id="datamart-preview" class="level3">
<h3 class="anchored" data-anchor-id="datamart-preview">Datamart Preview</h3>
<p>Below, we can tour the resulting datasets:</p>
<div id="4315c981" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="cb12-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> polars <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pl</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dev.duckdb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> con:</span>
<span id="cb12-5"></span>
<span id="cb12-6">    df_feat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'raw_feat'</span>).pl()</span>
<span id="cb12-7">    df_prep <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prep_feat'</span>).pl()</span>
<span id="cb12-8">    df_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_churn'</span>).pl()</span>
<span id="cb12-9">    df_snap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'main_snapshots.pred_churn_snapshot'</span>).pl()</span>
<span id="cb12-10">    df_fail <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'main_audit.accepted_values_serv_internet_service__DSL__Fiber_optic__No'</span>).pl()</span></code></pre></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Raw Training Data</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Prepared Features</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Predictions</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Snapshots</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-5" aria-controls="tabset-2-5" aria-selected="false">Failures</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div id="fad7bf70" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">df_feat.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 6944
Columns: 21
$ customer_id       &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ cat_train_test    &lt;str&gt; 'Train', 'Train', 'Train', 'Train', 'Train', 'Train', 'Train', 'Train', 'Train', 'Train'
$ tenure            &lt;i32&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62
$ phone_service     &lt;str&gt; 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes'
$ multiple_lines    &lt;str&gt; 'No phone service', 'No', 'No', 'No phone service', 'No', 'Yes', 'Yes', 'No phone service', 'Yes', 'No'
$ internet_service  &lt;str&gt; 'DSL', 'DSL', 'DSL', 'DSL', 'Fiber optic', 'Fiber optic', 'Fiber optic', 'DSL', 'Fiber optic', 'DSL'
$ online_security   &lt;str&gt; 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes'
$ online_backup     &lt;str&gt; 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes'
$ device_protection &lt;str&gt; 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No'
$ tech_support      &lt;str&gt; 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No'
$ streaming_tv      &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No'
$ streaming_movies  &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No'
$ gender            &lt;str&gt; 'Female', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male'
$ senior_citizen    &lt;i32&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
$ partner           &lt;str&gt; 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No'
$ dependents        &lt;str&gt; 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes'
$ contract          &lt;str&gt; 'Month-to-month', 'One year', 'Month-to-month', 'One year', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'Month-to-month', 'One year'
$ paperless_billing &lt;str&gt; 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No'
$ payment_method    &lt;str&gt; 'Electronic check', 'Mailed check', 'Mailed check', 'Bank transfer (automatic)', 'Electronic check', 'Electronic check', 'Credit card (automatic)', 'Mailed check', 'Electronic check', 'Bank transfer (automatic)'
$ monthly_charges   &lt;f64&gt; 29.85, 56.95, 53.85, 42.3, 70.7, 99.65, 89.1, 29.75, 104.8, 56.15
$ total_charges     &lt;f64&gt; 29.85, 1889.5, 108.15, 1840.75, 151.65, 820.5, 1949.4, 301.9, 3046.05, 3487.95
</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div id="3783234a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df_prep.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 6944
Columns: 47
$ oh__phone_service_No                       &lt;f64&gt; 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0
$ oh__phone_service_Yes                      &lt;f64&gt; 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0
$ oh__multiple_lines_No                      &lt;f64&gt; 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0
$ oh__multiple_lines_No_phone_service        &lt;f64&gt; 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0
$ oh__multiple_lines_Yes                     &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0
$ oh__internet_service_DSL                   &lt;f64&gt; 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0
$ oh__internet_service_Fiber_optic           &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0
$ oh__internet_service_No                    &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__online_security_No                     &lt;f64&gt; 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0
$ oh__online_security_No_internet_service    &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__online_security_Yes                    &lt;f64&gt; 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0
$ oh__online_backup_No                       &lt;f64&gt; 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0
$ oh__online_backup_No_internet_service      &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__online_backup_Yes                      &lt;f64&gt; 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0
$ oh__device_protection_No                   &lt;f64&gt; 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0
$ oh__device_protection_No_internet_service  &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__device_protection_Yes                  &lt;f64&gt; 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0
$ oh__tech_support_No                        &lt;f64&gt; 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0
$ oh__tech_support_No_internet_service       &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__tech_support_Yes                       &lt;f64&gt; 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0
$ oh__streaming_tv_No                        &lt;f64&gt; 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0
$ oh__streaming_tv_No_internet_service       &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__streaming_tv_Yes                       &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0
$ oh__streaming_movies_No                    &lt;f64&gt; 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0
$ oh__streaming_movies_No_internet_service   &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__streaming_movies_Yes                   &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0
$ oh__gender_Female                          &lt;f64&gt; 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0
$ oh__gender_Male                            &lt;f64&gt; 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0
$ oh__partner_No                             &lt;f64&gt; 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0
$ oh__partner_Yes                            &lt;f64&gt; 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0
$ oh__dependents_No                          &lt;f64&gt; 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0
$ oh__dependents_Yes                         &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0
$ oh__contract_Month_to_month                &lt;f64&gt; 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0
$ oh__contract_One_year                      &lt;f64&gt; 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0
$ oh__contract_Two_year                      &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ oh__paperless_billing_No                   &lt;f64&gt; 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0
$ oh__paperless_billing_Yes                  &lt;f64&gt; 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0
$ oh__payment_method_Bank_transfer_automatic &lt;f64&gt; 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0
$ oh__payment_method_Credit_card_automatic   &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0
$ oh__payment_method_Electronic_check        &lt;f64&gt; 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0
$ oh__payment_method_Mailed_check            &lt;f64&gt; 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0
$ remainder__tenure                          &lt;f64&gt; 1.0, 34.0, 2.0, 45.0, 2.0, 8.0, 22.0, 10.0, 28.0, 62.0
$ remainder__senior_citizen                  &lt;f64&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
$ remainder__monthly_charges                 &lt;f64&gt; 29.85, 56.95, 53.85, 42.3, 70.7, 99.65, 89.1, 29.75, 104.8, 56.15
$ remainder__total_charges                   &lt;f64&gt; 29.85, 1889.5, 108.15, 1840.75, 151.65, 820.5, 1949.4, 301.9, 3046.05, 3487.95
$ customer_id                                &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ model_version                              &lt;str&gt; '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0'
</code></pre>
</div>
</div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div id="95bd4553" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">df_pred.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 6944
Columns: 3
$ pred          &lt;f64&gt; 0.4350639304611832, 0.14068829294410534, 0.34994459204608575, 0.10898763570003211, 0.5811184463091195, 0.5483232741244137, 0.4043196897255257, 0.311830934981117, 0.3962726652389392, 0.1372128768125549
$ customer_id   &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ model_version &lt;str&gt; '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0'
</code></pre>
</div>
</div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<p>Score versioned and timestamped predictions from snapshots for auditability.</p>
<div id="9ad523d9" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">df_snap.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 6944
Columns: 7
$ pred                    &lt;f64&gt; 0.4350639304611832, 0.14068829294410534, 0.34994459204608575, 0.10898763570003211, 0.5811184463091195, 0.5483232741244137, 0.4043196897255257, 0.311830934981117, 0.3962726652389392, 0.1372128768125549
$ customer_id             &lt;str&gt; '7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '1452-KIOVK', '6713-OKOMC', '7892-POOKP', '6388-TABGU'
$ model_version           &lt;str&gt; '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0'
$ dbt_scd_id              &lt;str&gt; 'c4671964ba707c90a41d74f6f2ef75b7', '7dc40efa71bcee4795c7f54b3b5bc783', 'b05d4425f5d07106f1f2f2e782461f44', '3b919e27eb23ba54e200462af172e7da', 'eb6117ba3156a771b0e02e5e7bc644ab', 'ddae31e6abdabdd771ea4bbd1072fe55', 'aa7fe49fcbb5a937b44f7ac589b3ff34', 'da7eb2655934862105e8782e40ca5eb5', '882f945d0e265290e5976d4c8d04679e', '72f44f68e12a53baaf1d9ddd2469a616'
$ dbt_updated_at &lt;datetime[μs]&gt; 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000
$ dbt_valid_from &lt;datetime[μs]&gt; 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000, 2025-08-15 19:22:45.830000
$ dbt_valid_to   &lt;datetime[μs]&gt; 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00, 9999-12-31 00:00:00
</code></pre>
</div>
</div>
</div>
<div id="tabset-2-5" class="tab-pane" aria-labelledby="tabset-2-5-tab">
<p>What happens when the <code>internet_service</code> field is recoded in production data from “Fiber optic” to “Fiber” after training? If we are checking for <code>accepted_values</code>, we capture that change in our failures table before scoring on bad data!</p>
<div id="ad60aa36" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">df_fail.glimpse()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1
Columns: 2
$ value_field &lt;str&gt; 'Fiber'
$ n_records   &lt;i64&gt; 48
</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="dreaming-bigger" class="level3">
<h3 class="anchored" data-anchor-id="dreaming-bigger">Dreaming bigger</h3>
<p>This demo shows just <code>orbital</code> + <code>dbt</code>, but that’s just the beginning. Treating the whole MLOps process just like data processing means you can benefit from a wide range of integrated tools and capabilities, e.g.:</p>
<ul>
<li>data ingestion
<ul>
<li>retrieve training data for APIs with <code>dlt</code></li>
<li>ingest features from flatfiles on blob sources via the <code>dbt</code> <a href="https://hub.getdbt.com/dbt-labs/dbt_external_tables/latest/">external-tables</a> package</li>
</ul></li>
<li>better testing with dbt packages such as <a href="https://hub.getdbt.com/metaplane/dbt_expectations/latest/"><code>dbt-expectatons</code></a> (from Great Expectations)</li>
<li>logging and observability
<ul>
<li>snapshot features table as well as predictions table</li>
<li>use <code>dbt</code> packages like <a href="https://hub.getdbt.com/elementary-data/elementary/latest/">elementary</a> to write more run metadata to your warehouse</li>
</ul></li>
<li>orchestration with <code>Dagster</code>
<ul>
<li>unfurl your local <code>dbt</code> DAG into a broader pipeline</li>
<li>trigger more model-adjacent tasks from refitting, monitoring, etc.</li>
</ul></li>
<li>documentions with <code>dbt docs</code> (which can be <a href="https://github.com/emilyriederer/dbt_duckdb_quarto">enhanced with Quarto</a>)</li>
<li>reverse ETL with tools like HighTouch or Census to easily sync analytical data models into production systems like CRMs</li>
</ul>
</section>
</section>
<section id="sec-limitations" class="level2">
<h2 class="anchored" data-anchor-id="sec-limitations">Limitations</h2>
<p>While I see a lot of promise in model deployment to the database, it’s currently not without it’s limitations. Tobias Macey of the excellent <a href="https://www.dataengineeringpodcast.com/">Data Engineering Podcast</a> always ends his show by asking his guests (mostly tool developers): “When is <thing> not the right solution?” I’ll conclude by answering the same.</thing></p>
<p>There are many things I would consider if using <code>orbital</code> today for business use cases versus hobby projects:</p>
<ul>
<li><strong>Use Case</strong>: ML in Database only makes sense for batch predictions. <code>orbital</code> is not the right solution if there is a chance you’ll want realtime predictions</li>
<li><strong>Scale</strong>: SQL is generally good at optimizing large-scale data processing jobs. However, extremely large ensemble models may experience slower runtimes. If such a model was to be run at extreme scale, one would need to consider the relative latency<sup>8</sup> and cost<sup>9</sup> of this versus other solutions</li>
<li><strong>Algorithms</strong>: Right now <code>orbital</code> is mostly limited to <code>scikit-learn</code> models and select feature engineering steps (or <code>tidymodels</code> in R). This can be a challenge if you want to use other common algorithms. I’ve figured out some workarounds for <a href="../..\post/orbital-xgb"><code>xgboost</code></a> but at some point, the amount of hacking around the periphery reduces the “same code in dev and prod” benefits</li>
<li><strong>Precision</strong>: <code>orbital</code> uses <code>sklearn-onnx</code> which can create some issues when <a href="https://onnx.ai/sklearn-onnx/auto_tutorial/plot_ebegin_float_double.html">floating point precision</a>. It is easily tested how critical this is for your use case, but you may find corner cases where it is difficult to precisely recreate your local predictions – particularly for tree-based models where tiny perturbations send an observation down a different path.</li>
<li><strong>Bugs</strong>: <code>orbital</code> still has some bugs it’s working out and seems to still be building out its testing infrastructure. For example, at the time of writing this demo, I started out trying to use the <code>TargetEncoder()</code> which <a href="https://github.com/posit-dev/orbital/issues/62">failed unexpectedly</a> so I switched to the <code>OneHotEncoder()</code>. That’s fine for a demo, but I wouldn’t be so cavelier about letting tool limitations shape my modeling choices in real life.</li>
<li><strong>Governance</strong>: Similar to the downsides of <code>dbt</code>, the risk of lowering the barriers to entry to deploying a new data model or machine learning model is that it will be done carelessly or prolificly. As the demo above shows, a rigorous approach can add many data artifacts to your datamart and could risk causing bloat if done casually. Having the right controls to determine who should be allowed to deploy models of what materiality is key.</li>
</ul>
<p>The good news is, most of these downsides are fully testable. You can quickly and pretty robustly dual-validated <code>orbital</code>’s logic and cross-check prediction speed and accuracy from python and SQL environments. So, if the idea sounds intriguing, take it for a spin! There aren’t too many “unknown unknowns”. These packages are under active development and improving by the day. I am excited to continue following the progress and experimenting with this project.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>This post is cursed because “data modeling” and “predictive modeling” are completely different things, one involving data pipelines and the other involve machine learning. Both happen to be relevant here.↩︎</p></li>
<li id="fn2"><p>I say project versus package because <code>orbital</code> is really a “concept” with parallel but programmatically unrelated R and python implementations; the R project has been around for a but, but the python version is recently released .↩︎</p></li>
<li id="fn3"><p>Just want a few concrete ideas for stitching these tools together without the wind-up? Jump to Section&nbsp;3.1.↩︎</p></li>
<li id="fn4"><p>This list is, of course, non-comprehensive and coincidentally cherry-picked towards the problems which I’ll claim <code>orbital</code> might address. For a thoughtful and comprehensive take on MLOps, check out <a href="https://arxiv.org/abs/2209.09125">this excellent survey</a> by <a href="https://www.sh-reya.com/">Shreya Shankar</a> who, coincidentally enough, made MLOps the focus on her Stanford PhD in… Databases!↩︎</p></li>
<li id="fn5"><p>In my dual life volunteering on downballot campaigns, I also thing this pattern would be very effective to publish partisanship and turnout scores back to BigQuery, the beating heart of campaign data infrastructure.↩︎</p></li>
<li id="fn6"><p>Within a given database. SQL is a loosely enforced spec leading to an absurd amount of arbitrary uniqueness on top of ANSI. But, happily, so long as you aren’t switching databases, this does not matter.↩︎</p></li>
<li id="fn7"><p>If you run <code>dbt test</code> or <code>dbt test --store-failures</code>, you can find two such failure cases.↩︎</p></li>
<li id="fn8"><p>Or mitigate it through off-hours scheduling and materializing as a table versus a view↩︎</p></li>
<li id="fn9"><p>Comparing cost of database compute versus egress/ingress of pulling data from database to execute somewhere else↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>rstats</category>
  <category>python</category>
  <category>dbt</category>
  <category>sql</category>
  <category>data</category>
  <category>ml</category>
  <guid>https://emilyriederer.com/post/orbital-mlops/</guid>
  <pubDate>Sat, 16 Aug 2025 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/orbital-mlops/featured.png" medium="image" type="image/png" height="135" width="144"/>
</item>
<item>
  <title>Casual Inference Pod - Optimizing Data Workflows with Emily Riederer (Season 6, Episode 8)</title>
  <link>https://emilyriederer.com/talk/casual-pod/</link>
  <description><![CDATA[ 




<section id="quick-links" class="level2">
<h2 class="anchored" data-anchor-id="quick-links">Quick Links</h2>
<p><span><i class="bi bi-mic"></i> <a href="https://casualinfer.libsyn.com/site.pdf">Podcast Episode</a> </span></p>
<p>Casual Inference is a podcast on all things epidemiology, statistics, data science, causal inference, and public health. Sponsored by the American Journal of Epidemiology. As a guest on this episode, I discuss data science communication, the different challenges of causal analysis in industry versus academia, and much more.</p>


</section>

 ]]></description>
  <category>causal</category>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/casual-pod/</guid>
  <pubDate>Wed, 25 Jun 2025 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/casual-pod/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>A different type of DAG - data pipelines for epidemiology</title>
  <link>https://emilyriederer.com/talk/epi-pipes/</link>
  <description><![CDATA[ 




<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Quick Links</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Abstract</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Slides</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p><span><i class="bi bi-file-bar-graph"></i> <a href="slides.pdf">Slides</a> </span></p>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<p>This talk was part of a symposium on data science tools and opportunities for adoption in epidemiology. The full session description is provided below:</p>
<p>Most applied research and education in epidemiology does not yet benefit from modern data science. Fledgling epidemiologists may receive cutting-edge education on the theory of epidemiologic methods, but remain largely untrained in how to collect data effectively, how to apply modern analytical methods to real data sets, how to reproducibly document code and results, and how to effectively work in teams in a digital workplace. Despite their own nagging concerns, they may rely on Dr.&nbsp;Google as their training on algorithms, document study procedures in e-mail chains, store data in spreadsheets, copy-paste analytical code, hard-code observations per person into separate variables, and manually type out estimates into results tables – only to discover that they are requested to do it all over when three study participants turn out to be ineligible for an analysis.</p>
<p>This symposium will illustrate success stories on how to efficiently practice data science in epidemiology and how to teach it along the way. There will be no exhortations how Excel is bad and that good people practice code sharing. Instead, the symposium will discuss cutting-edge approaches and real-life use cases of how modern data science has made research and teaching more efficient. The goal is for attendees to bring home a sparkling, vetted toolkit of new ideas and tools for research and teaching.</p>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div id="slides" style="width:100%; aspect-ratio:16/11;">
<embed src="slides.pdf#zoom=Fit" width="100%" height="100%">
</div>
</div>
</div>
</div>



 ]]></description>
  <category>workflow</category>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/epi-pipes/</guid>
  <pubDate>Wed, 11 Jun 2025 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/epi-pipes/featured.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Crosspost: Data discovery doesn’t belong in ad hoc queries</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/data-discovery-ad-hoc/</link>
  <description><![CDATA[ 





<p>Credible documentation is the best tool for working with data. Short of that, labor (and computational) intensive validation may be required. Recently, I had the opportunity to expand on these ideas in a <a href="https://www.selectstar.com/resources/data-discovery-doesnt-belong-in-ad-hoc-queries">cross-post with Select Star</a>. I explore how a “good” data analyst can interrogate a dataset with expensive queries and, more importantly, how best-in-class data products eliminate the need for this.</p>
<p>My post is reproduced below.</p>
<hr>
<p>In the current environment of decreasing headcount and rising cloud costs, the benefits of data management are more objective and tangible than ever. Done well, data management can reduce the cognitive and computational costs of working with enterprise-scale data.</p>
<p>Analysts often jump into new-to-them tables to answer business questions. Without a robust data platform, this constant novelty leads analysts down one of two paths. Either they boldly gamble that they have found intuitive and relevant data or they painstakingly hypothesize and validate assumptions for each new table. The latter approach leads to more trustworthy outcomes, but it comes at the cost of human capital and computational power.</p>
<p>Consider an analyst at an e-commerce company asking the question “How many invoices did we generate for fulfilled orders to Ohio in June?” while navigating unfamiliar tables. In this post, we explore prototypical queries analysts might have to run to validate a new-to-them table. Many of these are “expensive” queries requiring full table scans. Next, we’ll examine how a data discovery platform can obviate this effort.</p>
<p>The impact of this inefficiency may range from a minor papercut to a major cost sink depending on the sizes of your analyst community, historical enterprise data, and warehouse.</p>
<section id="preventable-data-discovery-queries" class="level2">
<h2 class="anchored" data-anchor-id="preventable-data-discovery-queries">6 Preventable Data Discovery Queries</h2>
<section id="what-columns-are-in-the-table" class="level3">
<h3 class="anchored" data-anchor-id="what-columns-are-in-the-table">1. What columns are in the table?</h3>
<p>Without a good data catalog, analysts will first need to check what fields exist in a table. While there may be lower cost ways to do this like looking at a pre-rendered preview (ala BigQuery), using a DESCRIBE statement (ala Spark), or limiting their query to the first few rows, some analysts may default to requesting all the data.</p>
<pre><code>select *
from invoices;</code></pre>
</section>
<section id="is-the-table-still-live-and-updating" class="level3">
<h3 class="anchored" data-anchor-id="is-the-table-still-live-and-updating">2. Is the table still live and updating?</h3>
<p>After establishing that a table has potentially useful information, analysts should next wonder if the data is still live and updating. First they might check a date field to see if the table seems “fresh”.</p>
<pre><code>select max(order_date) 
from invoices;</code></pre>
<p>But, of course, tables often have multiple date fields. For example, an e-commerce invoice table might have fields for both the date an order was placed and the date the record was last modified. So, analysts may guess-and-check a few of these fields to determine table freshness.</p>
<pre><code>select max(updated_date) 
from invoices;</code></pre>
<p>After identifying the correct field, there’s still a question of refresh cadence. Are records added hourly? Daily? Monthly? Lacking system-level metrics and metadata on the upstream table freshness, analysts are still left in the dark. So, once again, they can check empirically by looking at the frequency of the date field.</p>
<pre><code>select max(updated_date), count(1) as n
from invoices
group by 1;</code></pre>
</section>
<section id="what-is-the-grain-of-the-table" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-grain-of-the-table">3. What is the grain of the table?</h3>
<p>Now that the table is confirmed to be usable, the question becomes how to use it. Specifically, to credibly query and join the table, analysts next must determine its grain. Often, they start with a guess informed by the business context and data modeling conventions, such as assuming an invoice table is unique by order_id.</p>
<pre><code>select count(1) as n, count(distinct order_id)
from invoices;</code></pre>
<p>‍However, if they learn that order_id has a different cardinality then the number of records, they must ask why. So, once again, they scan the full table to find examples of records with shared order_id values.</p>
<pre><code>select *
from invoices
qualify count(1) over (partition by order_id) &gt; 1
order by order_id
limit 10;</code></pre>
<p>Eyeballing the results of this query, the analysts might notice that the same order_id value can coincide with different ship_id values, as a separate invoice is generated for each part of an order when a subset of items is shipped. With this new hypothesis, the analyst iterates on the validation of the grain.</p>
<pre><code>select count(1) as n, count(distinct order_id, ship_id)
from invoices;</code></pre>
</section>
<section id="what-values-can-categorical-variables-take" class="level3">
<h3 class="anchored" data-anchor-id="what-values-can-categorical-variables-take">4. What values can categorical variables take?</h3>
<p>The prior questions all involved table structure. Only now can an analyst finally begin to investigate the table’s content. A first step might be to understand the valid values for categorical variables. For example, if our analyst wanted to ensure only completed orders were queried, they might inspect the potential values of the order_status_id field to determine which values to include in a filter.</p>
<pre><code>select distinct order_status_id
from invoices;</code></pre>
<p>They’ll likely repeat this process for many categorical variables of interest. Since our analyst is interested in shipments specifically to Ohio, they might also inspect the cardinality of the ship_state field to ensure they correctly format the identifier.</p>
<pre><code>select distinct ship_state
from invoices;</code></pre>
</section>
<section id="do-numeric-columns-have-nulls-or-sentinel-values-to-encode-nulls" class="level3">
<h3 class="anchored" data-anchor-id="do-numeric-columns-have-nulls-or-sentinel-values-to-encode-nulls">5. Do numeric columns have nulls or ‘sentinel’ values to encode nulls?</h3>
<p>Similarly, analysts may wish to audit other variables for null handling or sentinel values by inspecting column-level statistics.</p>
<pre><code>select distinct ship_state
from invoices;</code></pre>
</section>
<section id="is-the-data-stored-with-partitioning-or-clustering-keys" class="level3">
<h3 class="anchored" data-anchor-id="is-the-data-stored-with-partitioning-or-clustering-keys">6. Is the data stored with partitioning or clustering keys?</h3>
<p>Inefficient queries aren’t only a symptom of ad hoc data validation. More complex and reused logic may also be written wastefully when table metadata like partitioning and clustering keys is not available to analysts. For example, an analyst might be able to construct a reasonable query filtering either on a shipment date or an order date, but if only one of these is a partitioning or clustering key, different queries could have substantial performance differences.</p>
</section>
</section>
<section id="understanding-your-data-without-relying-on-queries" class="level2">
<h2 class="anchored" data-anchor-id="understanding-your-data-without-relying-on-queries">Understanding Your Data Without Relying on Queries</h2>
<p>Analysts absolutely should ask themselves these types of questions when working with new data. However, it should not be analysts’ job to individually answer these questions by running SQL queries. Instead, best-in-class data documentation can provide critical information through a data catalog like Select Star.</p>
<section id="what-columns-are-in-the-table-and-do-we-need-a-table" class="level3">
<h3 class="anchored" data-anchor-id="what-columns-are-in-the-table-and-do-we-need-a-table">1. What columns are in the table? And do we need a table?</h3>
<p>Comprehensive search across all of an organization’s assets can help users quickly identify the right resources based on table names, field names, or data descriptions. Even better, search can incorporate observed tribal knowledge of table popularity and common querying patterns to prioritize the most relevant results. Moreover, when search also includes downstream data products like pre-built reports and dashboards, analysts might sometimes find an answer to their question exists off the shelf.</p>
</section>
<section id="is-the-table-still-live-and-updating-and-are-its-own-sources-current" class="level3">
<h3 class="anchored" data-anchor-id="is-the-table-still-live-and-updating-and-are-its-own-sources-current">2. Is the table still live and updating? And are its own sources current?</h3>
<p>Data is not a static artifact so metadata should not be either. After analysts identify a candidate table, they should have access to real-time operational information like table usage, table size, refresh date, and upstream dependencies to help confirm whether the table is a reliable resource.</p>
<p>Ideally, analysts can interrogate not just the freshness of a final table but also its dependencies by exploring the table’s data lineage.</p>
</section>
<section id="what-is-the-grain-of-the-table-and-how-does-it-relate-to-others" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-grain-of-the-table-and-how-does-it-relate-to-others">3. What is the grain of the table? And how does it relate to others?</h3>
<p>Table grain should be clearly documented at the table level and emphasized in the data dictionary via references to primary and foreign keys. Beyond basic documentation, entity-relationship (ER) diagrams will help analysts gain a richer mental model of grains of how they can use these primary-foreign key relationships to link tables to craft information with the desired grain and fields. Alternatively, they can glean this information from the wisdom of the crowds if they have access to how others have queried and joined the data previously.</p>
</section>
<section id="what-values-can-categorical-variables-take-do-numeric-columns-have-nulls-or-sentinel-values-to-encode-nulls" class="level3">
<h3 class="anchored" data-anchor-id="what-values-can-categorical-variables-take-do-numeric-columns-have-nulls-or-sentinel-values-to-encode-nulls">4. What values can categorical variables take? Do numeric columns have nulls or ‘sentinel’ values to encode nulls?</h3>
<p>Information about proper expectations and handling of categorical and null values may be published as field definitions, pointed to lookup tables, implied in data tests, or illustrated in past queries. To drive consistency and offload redundant work from data producers, such field definitions can be propagated from upstream tables.</p>
</section>
<section id="is-the-data-stored-with-partitioning-or-clustering-keys-1" class="level3">
<h3 class="anchored" data-anchor-id="is-the-data-stored-with-partitioning-or-clustering-keys-1">‍5. Is the data stored with partitioning or clustering keys?</h3>
<p>Analysts cannot write efficient code if they don’t know where the efficiency gains lie. Table-level documentation should clearly highlight the use of clustering or partitioning files so analysts can use the most impactful variables in filters and joins. Here, consistency of documentation is paramount; analysts may not always be incented to care about query efficiency, so if this information is hard to find or rarely available, they can be easily dissuaded from looking.</p>
<p>Beyond a poor user experience, poor data discoverability creates inefficiency and added cost. Even if you don’t have large scale historical data or broad data user communities today, slow queries and tedious work still detract from data team productivity while introducing context-switching and chaos. By focusing on improving data discoverability, you can streamline workflows and enhance the overall efficiency of your data operations.</p>


</section>
</section>

 ]]></description>
  <category>data</category>
  <category>workflow</category>
  <category>elt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/data-discovery-ad-hoc/</guid>
  <pubDate>Thu, 18 Jul 2024 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/data-discovery-ad-hoc/featured.png" medium="image" type="image/png" height="76" width="144"/>
</item>
<item>
  <title>Crosspost: Why You Need Data Documentation in 2024</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/docs-personas/</link>
  <description><![CDATA[ 





<p>We’ve all worked with poorly documented dataset, and we all know it isn’t pretty. However, it’s surprisingly easy for teams to continue to fall into “documentation debt” and deprioritize this foundational work in favor of flashy new projects. These tradeoff discussions may become even more painful in 2024 as teams are continually asked to do more with less.</p>
<p>Recently, I had the opportunity to articulate some of the underappreciated benefits of data documentation in a <a href="https://www.selectstar.com/blog/why-you-need-data-documentation-in-2024">cross-post with Select Star</a>. This builds on my prior post showing that <a href="../..\post/docs-closer-than-you-think/">documentation can be strategically created throughout the data development process</a>. To make the case for taking those “raw” documentation resources to a polished final form, I return to the jobs-to-be-done framework that I’ve previously employed to talk about <a href="../..\post/team-of-packages/">the value of innersource packages</a>. In this perspective, documentation is like hiring an extra resource (or more!) to your team.</p>
<p>Some of the jobs discussed are:</p>
<ul>
<li>Developer Advocacy and Product Evangelism for users
<ul>
<li>Users think data doesn’t exist if they can’t find it, they think data is broken if they misinterpret it</li>
<li>Documentation is both a “user interface” to make data usage easy and a bulwark against confusion and frustration</li>
</ul></li>
<li>Producct and Project Management for developers
<ul>
<li>Data intent can “drift” over time</li>
<li>As teams evolve and collaborate, this risks initial intent getting lost and poluted (after all, what really is a “customer”?)</li>
<li>Documentation serves as a contract and coach for one or more teams to force clarity and consistency of intent</li>
</ul></li>
<li>Chief of Staff oversight for data leaders
<ul>
<li>Leaders face increasing demands in data governance: navigating changing privacy regulations, fighting decaying data quality, and discerning their next strategic investments</li>
<li>Documentation is their command center to understand what data assets exists and where to better spot risks and opportunities</li>
</ul></li>
</ul>
<p>If you or your team works on data documentation, I’d love to hear what other “jobs” you have found that data documentation performs in your organization.</p>



 ]]></description>
  <category>data</category>
  <category>workflow</category>
  <category>elt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/docs-personas/</guid>
  <pubDate>Mon, 15 Jan 2024 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/docs-personas/featured.PNG" medium="image"/>
</item>
<item>
  <title>Crosspost: Why you’re closer to data documentation than you think</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/docs-closer-than-you-think/</link>
  <description><![CDATA[ 





<p>Documentation can be a make-or-break for the success of a data initiative, but it’s too often considered an optional nice-to-have. I’m a big believer that writing is thinking. Similarly, documenting is planning, executing, and validating.</p>
<p>Previously, I’ve explored how <a href="https://emilyriederer.netlify.app/post/latent-lasting-documentation/">we can create latent and lasting documentation</a> of data products and how <a href="https://emilyriederer.netlify.app/post/column-name-contracts/">column names can be self documenting</a>.</p>
<p>Recently, I had the opportunity to expand on these ideas in a <a href="https://www.selectstar.com/blog/why-youre-closer-to-data-documentation-than-you-think">cross-post with Select Star</a>. I argue that teams can produce high-quality and maintainable documentation with low overhead with a form of “documentation-driven development”. That is, smartly structuring and re-using artifacts from the development process into long-term documentation. For example:</p>
<ul>
<li>At the planning stage:
<ul>
<li>Structuring requirements docs in the form of data dictionaries</li>
<li>Creating early alignment on higher-order concepts like entity definitions (and <em>writing them down</em>)</li>
<li>Mentally beta testing data usability with an entity-relationship diagram</li>
</ul></li>
<li>At the development stage:
<ul>
<li>Ensuring relevant parts of internal “development documentation” (e.g.&nbsp;dbt column definitions, docstrings) are published to a format and location accessible to users</li>
<li>With different information but similar motivation to ER diagrams, sharing the full orchestration DAG to help users trace column-level lineage and internalize how each field maps to a real-world data generating process</li>
<li>Sharing data tests being executed (the “user contract”) and their results</li>
</ul></li>
<li>Throughout the lifecycle:
<ul>
<li>Answering questions “in public” (e.g.&nbsp;Slack versus email) to create a searchable collection of insights</li>
<li>Producing table usage statistics to help large, decentralized orgs capture the “wisdom of the crowds”</li>
</ul></li>
</ul>
<p>If you or your team works on data documentation, I’d love to hear what other patterns you’ve found to collect useful documentation assets during a data development process.</p>



 ]]></description>
  <category>data</category>
  <category>workflow</category>
  <category>elt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/docs-closer-than-you-think/</guid>
  <pubDate>Fri, 05 Jan 2024 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/docs-closer-than-you-think/featured.PNG" medium="image"/>
</item>
<item>
  <title>Data Downtime Horror Stories Panel</title>
  <link>https://emilyriederer.com/talk/data-downtime/</link>
  <description><![CDATA[ 




<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>In October, I joined a Halloween-themed panel along with Chad Sanderson and Joe Reis to discuss our horror stories of data quality gone wrong and how to build successful data quality strategies in large organizations. Key takeaways are summarized on <a href="https://www.montecarlodata.com/blog-scary-data-quality-stories-7-tips-for-preventing-your-own-data-downtime-nightmare/">Monte Carlo’s blog</a>.</p>


</section>

 ]]></description>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/data-downtime/</guid>
  <pubDate>Mon, 23 Oct 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/data-downtime/featured.PNG" medium="image"/>
</item>
<item>
  <title>Scaling Personalized Volunteer Emails</title>
  <link>https://emilyriederer.com/talk/midterm-email/</link>
  <description><![CDATA[ 




<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Quick Links</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Abstract</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Slides</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" aria-controls="tabset-1-4" aria-selected="false">Video</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p><span><i class="bi bi-file-bar-graph"></i> <a href="slides.pdf">Slides</a> </span><br>
<span><i class="bi bi-play"></i> <a href="https://youtu.be/5UGUcgxTWTM">Video</a> </span></p>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<p>In this four-minute lightning talk, I explain how Two Million Texans used components of our existing data stack to provide personalized success metrics and action recommendations to over 5,000 volunteers in the lead up to the 2022 midterm elections. I briefly describe our pipeline and how we frontloaded key computational steps in BigQuery to circumvent limitations of downstream tools.</p>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div id="slides" style="width:100%; aspect-ratio:16/11;">
<embed src="slides.pdf#zoom=Fit" width="100%" height="100%">
</div>
</div>
<div id="tabset-1-4" class="tab-pane" aria-labelledby="tabset-1-4-tab">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/5UGUcgxTWTM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</div>



 ]]></description>
  <category>data</category>
  <category>elt</category>
  <guid>https://emilyriederer.com/talk/midterm-email/</guid>
  <pubDate>Wed, 21 Jun 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/midterm-email/featured.png" medium="image" type="image/png" height="80" width="144"/>
</item>
<item>
  <title>Industry information management for causal inference</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/causal-data/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/causal-data/featured.png" class="img-fluid figure-img"></p>
<figcaption>Data strategy motivated by causal methods</figcaption>
</figure>
</div>
<p><em>This post summarizes the final third of my talk at Data Science Salon NYC in June 2023. Please see the <a href="../..\talk/causal-design-patterns">talk details</a> for more content.</em></p>
<p>Techniques of observational causal inference are becoming increasingly popular in industry as a complement to experimentation. Causal methods offer the promise of accelerating measurement agendas and facilitating the estimation of previously un-measurable targets by allowing analysts to extract causal insights from “found” data (e.g.&nbsp;observational data collected without specific intent). However, if executed without careful attention to their assumptions and limitations, they can lead to spurious conclusions.</p>
<p>Both experimental and observational methods attempt to address the <strong>fundamental problem of causal inference</strong>: that is, the fact that for a given treatment of interest, we can never “see” the <em>individual-level outcome</em> both for the case when an individual received a treatment and a counterfactual scenario in which <em>for the same individual in the exact same context</em> that treatment was withheld. Some literature casts this as a “missing data” problem.<sup>1</sup> Counterfactual data is uncollectable; however, this fundamental missingness can be partially mitigated by diligent collection of <em>other</em> types of quantitative and qualitative information to control for confounding<sup>2</sup> and interrogate assumptions.</p>
<p>In this post, I argue that industry has unique advantages when using causal techniques over the social science disciplines that originated many foundational methods due to industry’s (theoretically) superior ability to observe and capture relevant supplemental data and context. Examining the implicit assumptions in common <a href="../..\post/causal-design-patterns">causal design patterns</a> motivates the types of proactive enterprise information management – including data, metadata, and knowledge management – that will help preserve the raw inputs that future data scientists will need to effectively deploy causal techniques on historical data and answer questions that our organizations cannot even anticipate today. By casting an intentionally wide net on what information we observationally collect, we increase the likelihood that the future “found” data will have what those analysts need to succeed.</p>
<section id="why-industry-needs-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="why-industry-needs-causal-inference">Why industry needs causal inference</h2>
<p><img src="https://emilyriederer.com/post/causal-data/why-not-experiment.png" class="img-fluid"></p>
<p>Industry data science tends to highly value the role of A/B testing and experimentation. However, there are many situations where experimentation is not an optimal approach to learning. Experiments can be infeasible if we worry about the ethics or reputational risk of offering disparate customer treatments; they may be impractical in situations that are hard to randomize or avoid spillover effects; they can be costly to run and configure either in direct or opportunity costs; and, finally, they can just be <em>slow</em> if we wish to measure complex and long-term impacts on customer behaviors (e.g.&nbsp;retention, lifetime value).</p>
</section>
<section id="what-causal-methods-require" class="level2">
<h2 class="anchored" data-anchor-id="what-causal-methods-require">What causal methods require</h2>
<p><img src="https://emilyriederer.com/post/causal-data/patterns-and-variation.png" class="img-fluid"></p>
<p>These limitations are one of the reasons why observational causal inference is gaining increasing popularity in industry. Methods of observational causal inference allows us to estimate treatment effects without randomized controlled experimentation by using existing historical data. At the highest level, these methods work by replacing <em>randomization</em> with strategies to exploit other forms of <em>semi-random variation</em> in historical exposures of a population to a treatment. Since this semi-random <em>variation</em> could be susceptible to confounding, observational methods supplement variation with <em>additional data</em> to control for other observable sources of bias in our estimates and <em>contextual assumptions</em> about the data generating process.</p>
<p>My previous post on <a href="../..\post/causal-design-patterns">causal design patterns</a> outlines a number of foundational causal methods, but I’ll briefly recap to emphasize the different ways that sources of variation, data, and context are used:</p>
<ul>
<li><strong>Stratification and Inverse Propensity Score Weighting</strong>:
<ul>
<li>Exploits “similar” populations of treated and untreated individuals</li>
<li>Assumes we can observe and control for common causes of the treatment and the outcome</li>
</ul></li>
<li><strong>Regression Discontinuity</strong>:
<ul>
<li>Exploits a sharp, semi-arbitrary cut-off between treated and untreated individuals</li>
<li>Assumes that the outcome is continuous with respect to the assigment variable and the assignment mechanism is unknown to individuals (to avoid self-selection)</li>
</ul></li>
<li><strong>Difference in Differences</strong>:
<ul>
<li>Exploits variation between <em>behavior over time</em> of treated and untreated <em>groups</em></li>
<li>Assumes that the treatment assignment is unrelated to expected future outcomes and that the treatment is well-isolated to the treatment group</li>
</ul></li>
</ul>
<p>Notably, the assumptions mentioned above are largely untestable statistically (e.g.&nbsp;not like testing for normality or multicolinearity) but rely on knowledge of past strategies and policies that guided differential treatment in historical data.<sup>3</sup></p>
</section>
<section id="industrys-unique-advantages-deploying-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="industrys-unique-advantages-deploying-causal-inference">Industry’s unique advantages deploying causal inference</h2>
<p><img src="https://emilyriederer.com/post/causal-data/industry-advantages.png" class="img-fluid"></p>
<p>Many causal methods originated in fields like epidemiology, economics, political science, and other social sciences. In such fields, direct experimentation is often impossible and even first-hand data collection is less common. Often, researchers may have to rely on pre-existing data sources like censuses, surveys, and administrative data (e.g.&nbsp;electronic health records).</p>
<p>Despite the lineage of these methods, industry has many advantages over traditional research fields in using them because each company controls the entire “universe” in which its customers exist. This should in theory provide a distinct advantage when collecting each of the three “ingredients” that causal methods use to replace randomization:</p>
<ul>
<li><strong>Variation</strong>: We control customer engagement strategies through methods like customer segmentation or models. Subsequent customer treatments are completely known to us but inherently have some arbitrary, judgmental component to exploit</li>
<li><strong>Data</strong>: We tend to be able to collect more measurements of our customers both as a snapshot (more variety in fields) and longitudinally (more observations over time) that can be brought into our analyses to control for confounders<sup>4</sup>, reduce other sources of variation in our estimate, and have additional ‘out of time’ data left over to conduct forms of validation like placebo tests</li>
<li><strong>Context</strong>: We tend to know how past strategies were set-up, how they looked to individuals involved, and <em>why</em> those decisions were made. This can be critical in reasoning whether our assumptions hold</li>
</ul>
<p>However, to convert this theoretical benefit to a practical one requires information management.</p>
</section>
<section id="data-management-for-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="data-management-for-causal-inference">Data management for causal inference</h2>
<p><img src="https://emilyriederer.com/post/causal-data/featured.png" class="img-fluid"></p>
<p>While all causal methods will be enhanced with better enterprise information management, it’s easiest to see the motivation by thinking back to specific examples. Causal inference can benefit from better data, metadata, and knowledge management. These are illustrated by propensity score weighting, regression discontinuity, and diff-in-diff respectively.</p>
<p><strong>Integrated Data Management</strong></p>
<p>Earlier, we posited that one advantage that industry has over academia for causal inference is access to richer historical data sources as a higher level of resolution (more measures per individual at more time points). A rich set of customer measures is critical for stratification and propensity score weighting where we attempt to control for selection on observables by balancing populations along dimensions that might be common causes of treatment assignment and outcome. (And, we may also wish to control for other unrelated sources of variation that effect only the outcome to develop more precise estimates.)</p>
<p>However, this is only true if customer data is proactively <em>collected, cleaned, and harmonized</em> across sources in the true spirit of a customer 360 view. Enterprises may collect data about customers from many different operational systems – for example, demographic information provided at registration, digital data on their logins and web activity, campaign data on attempted customer touchpoints and engagement, behavioral or fulfillment data on purchases / subscription renewals / etc. Any of these sources could be useful “observables” that help close confounding pathways in our analyses.</p>
<p>To make this data useful and accessible for analysis, it must be <em>proactively integrated</em> into a common source like a data warehouse, <em>well-documented</em> to help future users understand the nuances of each system, <em>harmonized</em> so fields have standard definitions (e.g.&nbsp;common definitions of an “account” and a “customer”), and <em>unified</em> by using techniques like entity resolution to ensure all sources share common identifiers so that they can be merged for analysis.</p>
<p><strong>Metadata Management</strong></p>
<p>Beyond those “typical” sources of customer data, our past customer strategies create data beyond the data directly generated by our customers. Metadata about past campaigns such as precise business logic on the different treatments offered (e.g.&nbsp;if sending customers a discount, what algorithmically determined the amount?), the campaign targeting and segmentation (e.g.&nbsp;What historical behaviors were used to segments customers? Was treatment determined by a predictive model?), and launch timing can all be critical to clearly identifying those sources of variation that we wish to exploit. For example, we might know that we once ran an re-engagement campaign to attempt the nudge interaction from customers who didn’t log-in to a website for some amount of time, but knowing whether that campaign was targeting customers &gt;30 days inactive or &gt;45 days inactive impacts our ability to analyze it with a regression discontinuity.</p>
<p>This means that we need to <em>treat metadata as first-class data</em> and ensure that it is extracted from operational source systems (or intent docs, config files, etc.), structured in a machine-readable format, and preserved in analytical data stores along with our customer data.</p>
<p>The importance of “metadata as data” extends beyond business-as-usual organization strategies. We can also fuel future causal inference with better metadata management of past formal experiments and execution errors.</p>
<p>As discussed above, formal experiments may represent a substantial <em>investment</em> in company resources so the data collected from them should be regarded as an <em>asset</em>. Beyond their utility for one-time reads and decisions, experiment designs and results should be carefully catalogued along with the assigned treatment group and the randomization criteria (such as fields characterizing <a href="https://www.census.gov/programs-surveys/acs/technical-documentation/user-notes/2022-07.html">sampling weights</a> as provided in US Census data). This can support future <em>observational</em> analysis of past experiments, including generalizing and transporting results to different populations.</p>
<p>Furthermore, even <em>mistakes</em> in executing past strategies may become “natural experiments” to help businesses understand scenarios that they might never have prioritized for testing. So, machine-readable incident logs and impacted populations can be useful as well.</p>
<p><strong>Knowledge Management</strong></p>
<p>Of course, not <em>all</em> information can be condensed into a nice, machine-readable spreadsheet. Methods like difference-in-differences illustrate how conceptual context can also help us battle-test assumptions like whether the decision-to-treat could have spilled over into the control population or been influenced by an anticipated change in the future outcome. This is the one area where industry may sometimes <em>lag</em> social sciences in information since some population-level treatments like a state law or local ordinance often have documented histories through the legislative process, news coverage, and historical knowledge about their implementation.</p>
<p>Industry can catch up on knowledge management by documenting and preserving in a centralized knowledge repository key information about strategic decisions undertaken, the motivating factors, and the anticipated customer experience. Such documents are inevitably created when working on new projects through memos ad decks intended to communicate the business case, intent, and expected customer experience. However, proactively figuring out how to <em>organize and index</em> this information through a classification system and <em>democratize access</em> through centralized knowledge repositories is critical to giving future users entree to this tribal knowledge. Projects like Airbnb’s <a href="https://github.com/airbnb/knowledge-repo">Knowledge Repository</a> suggest what such a system might look like in practice.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For example, see https://arxiv.org/abs/1710.10251↩︎</p></li>
<li id="fn2"><p>If you’ve heard of ‘selection on observables’ in causal literature, richer data means observables!↩︎</p></li>
<li id="fn3"><p>There are some exceptions to this like placebo tests, bunching checks, etc.↩︎</p></li>
<li id="fn4"><p>Notable, the availability of more data absolutely does <em>not</em> mean that we should simply “dump in” all the data we have. Controlling for certain variables like colliders is counterproductive.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>causal</category>
  <category>data</category>
  <guid>https://emilyriederer.com/post/causal-data/</guid>
  <pubDate>Tue, 30 May 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/causal-data/featured.png" medium="image" type="image/png" height="60" width="144"/>
</item>
<item>
  <title>DataFold Data Quality Meet Up</title>
  <link>https://emilyriederer.com/talk/meetup-datafold/</link>
  <description><![CDATA[ 




<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Quick Links</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Abstract</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Slides</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" aria-controls="tabset-1-4" aria-selected="false">Video</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p><span><i class="bi bi-file-bar-graph"></i> <a href="slides.pdf">Slides</a> </span><br>
<span><i class="bi bi-play"></i> <a href="https://www.youtube.com/watch?v=uAe74zdLHbM">Video</a> </span></p>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<p>This is the full recording from Datafold’s 9th Data Quality Meetup on Thursday, May 11th, 2023, which was focused on ‘Running dbt at scale’.</p>
<p>Following our usual structure, each of our speakers present a lightning talk and then we transition into a panel discussion moderated by Gleb Mezhanskiy - who pulls in the audiences’ questions.</p>
<p>We had 6 guest speakers &amp; panelists: 1. Emily Riederer @ Capital One - “Operationalizing Column Name Contracts” 2. Felix Kreitschmann and Jorrit Posor @ FINN Auto - “Supercharging Analytics Engineers: How to save time and prevent technical debt by automating CI checks” 3. Alexandra Gronemeyer @ Airbyte - “adopting and running dbt within a small data team at Airbyte” 4. Jason Jones @ Virgin Media O2 - “Zero to 200: scaling analytics engineering within an enterprise” 5. Sung Won Chung @ dbt Labs - “Experiences implementing dbt at scale”</p>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div id="slides" style="width:100%; aspect-ratio:16/11;">
<embed src="slides.pdf#zoom=Fit" width="100%" height="100%">
</div>
</div>
<div id="tabset-1-4" class="tab-pane" aria-labelledby="tabset-1-4-tab">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/uAe74zdLHbM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</div>



 ]]></description>
  <category>elt</category>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/meetup-datafold/</guid>
  <pubDate>Fri, 12 May 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/meetup-datafold/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Crosspost: The Art of Abstraction in ETL</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/abstraction-airbyte/</link>
  <description><![CDATA[ 





<p><img src="https://emilyriederer.com/post/abstraction-airbyte/featured.PNG" class="img-fluid"></p>
<p>I previously shared the first in my three-part series of guest posts on Airbyte’s developer blog about ETL. The first focused on errors in data extraction. The next two focused on the countless, small decisions one makes when loading data, and finally the DataOps burden to keep things up-and-running.</p>
<p>This post serves only to serve as a quick reference to those posts:</p>
<ul>
<li><a href="https://airbyte.com/blog/dodging-data-extraction-errors">Dodging extraction errors</a></li>
<li><a href="https://airbyte.com/blog/loading-data-in-etl">Making sound loading decisions</a></li>
<li><a href="https://airbyte.com/blog/etl-good-practices">Keeping the good things going</a></li>
</ul>



 ]]></description>
  <category>data</category>
  <category>workflow</category>
  <category>elt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/abstraction-airbyte/</guid>
  <pubDate>Wed, 03 May 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/abstraction-airbyte/featured.PNG" medium="image"/>
</item>
<item>
  <title>The Art of Abstraction in ETL: Dodging Data Extraction Errors</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/abstraction-extraction/</link>
  <description><![CDATA[ 





<p><img src="https://emilyriederer.com/post/abstraction-extraction/featured.png" class="img-fluid"></p>
<p>Whenever I think about data developer tooling, I always like to take the perspectives of:</p>
<ol type="1">
<li>Understanding what higher-level abstractions that it provides that help eliminate rote work or reduce mental overhead for data teams. In the spirit of <a href="../..\post/team-of-packages/">my post on the jobs-to-be-done of innersource analysis tools</a>, this can be framed as what ‘jobs’ that tool can be hired to do (and with what level of responsibility and autonomy)</li>
<li>Interrogating the likely failure modes in the data stack based on the mechanics of the system, in the spirit of my <a href="../..\post/grouping-data-quality/">call for hypothesis-driven data quality testing</a></li>
</ol>
<p>These two themes motivated my recent guest post for Airbyte’s developer blog on <a href="https://airbyte.com/blog/dodging-data-extraction-errors">The Art of Abstraction in ETL: Dodging Data Extraction Errors</a>. In this post, I argue:</p>
<blockquote class="blockquote">
<p>Cooking a meal versus grocery shopping. Interior decorating versus loading the moving van. Transformation versus Extract-Load. It’s human nature to get excited by flashy outcomes and, consequently, the most proximate processes that evidently created them.</p>
</blockquote>
<blockquote class="blockquote">
<p>This pattern repeats in the data world. Conferences, blog posts, corporate roadmaps, and even budgets focus on data transformation and the allure of “business insights” that might follow. The steps to extract and load data are sometimes discounted as a trivial exercise of scripting and scheduling a few API calls.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, the elegance of Extract-Load is not just the outcome but the execution – the art of things not going wrong. Just as interior decorating cannot salvage a painting damaged in transit or a carefully planned menu cannot be prepared if half of the ingredients are out-of-stock, the Extract-Load steps of data processing have countless pitfalls which can sideline data teams from their ambitious agendas and aspirations.</p>
</blockquote>
<p>I then go on to explore common challenges in successfully extracting data from an API and the abstractions that can aid in this process.</p>
<p>Please check out the full post on Airbyte’s site! I hope it resonates.</p>



 ]]></description>
  <category>data</category>
  <category>workflow</category>
  <category>elt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/abstraction-extraction/</guid>
  <pubDate>Wed, 22 Mar 2023 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/abstraction-extraction/featured.PNG" medium="image"/>
</item>
<item>
  <title>Crosspost: Power up your data quality with grouped checks</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/grouping-data-quality-crosspost/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/grouping-data-quality-crosspost/featured.jpg" class="img-fluid figure-img"></p>
<figcaption>Photo credit to <a href="https://unsplash.com/@greysonjoralemon">Greyson Joralemon</a> on Unsplash</figcaption>
</figure>
</div>
<p>I’ve written previously about the <a href="../..\post/grouping-data-quality/">unreasonably effectiveness of grouping in data quality checks</a> and <a href="../..\post/grouping-data-quality-update/">implementing such checks in dbt</a>. To publicize my <a href="https://github.com/dbt-labs/dbt-utils/pull/633">merged pull request</a> for this feature in <code>dbt-utils</code> package, I summarized my thinking on the topic on dbt’s Developer Blog.</p>
<p>Check out the post <a href="https://docs.getdbt.com/blog/grouping-data-tests#grouped-checks">here</a>.</p>



 ]]></description>
  <category>data</category>
  <category>dbt</category>
  <category>crosspost</category>
  <guid>https://emilyriederer.com/post/grouping-data-quality-crosspost/</guid>
  <pubDate>Tue, 17 Jan 2023 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/grouping-data-quality-crosspost/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The Data (error) Generating Process</title>
  <link>https://emilyriederer.com/talk/data-error-gen/</link>
  <description><![CDATA[ 




<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Quick Links</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Abstract</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Slides</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" aria-controls="tabset-1-4" aria-selected="false">Video</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p><span><i class="bi bi-file-bar-graph"></i> <a href="slides.pdf">Slides</a> </span><br>
<span><i class="bi bi-play"></i> <a href="https://www.youtube.com/watch?v=LkfP4dEv11Q">Video</a> </span><br>
<span><i class="bi bi-pencil"></i> <a href="../..\post/grouping-data-quality/">Post - Why Group Data Tests?</a> </span><br>
<span><i class="bi bi-pencil"></i> <a href="../..\post/grouping-data-quality-update/">Post - Grouped Data Tests in dbt-utils</a> </span></p>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<p>Statisticians often approach probabilistic modeling by first understanding the conceptual data generating process. However, when validating messy real-world data, the technical aspects of the data generating process is largely ignored.</p>
<p>In this talk, I will argue the case for developing more semantically meaningful and well-curated data tests by incorporating both conceptual and technical aspects of “how the data gets made”.</p>
<p>To illustrate these concepts, we will explore the NYC subway rides open dataset to see how the simple act of reasoning about real-world events their collection through ETL processes can help craft far more sensitive and expressive data quality checks. I will also illustrate how to implement such checks based on new features which I recently contributed to the open-source <code>dbt-utils</code> package.</p>
<p>Audience members should leave this talk with a clear framework in mind for ideating better tests for their own pipelines.</p>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div id="slides" style="width:100%; aspect-ratio:16/11;">
<embed src="slides.pdf#zoom=Fit" width="100%" height="100%">
</div>
</div>
<div id="tabset-1-4" class="tab-pane" aria-labelledby="tabset-1-4-tab">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LkfP4dEv11Q" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</div>



 ]]></description>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/data-error-gen/</guid>
  <pubDate>Sat, 12 Nov 2022 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/data-error-gen/featured.png" medium="image" type="image/png" height="54" width="144"/>
</item>
<item>
  <title>Goin’ to Carolina in my mind (or on my hard drive)</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/duckdb-carolina/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/duckdb-carolina/featured.jpg" class="img-fluid figure-img"></p>
<figcaption>Photo Credit to <a href="https://unsplash.com/@element5digital">Element5 Digital</a> on Unsplash</figcaption>
</figure>
</div>
<p>There comes a time in every analyst’s life when data becomes too big for their laptop’s RAM. While open-source tools like R, python, and SQL have made “team of one” data analysts ever more powerful, analysts abilities to derive value from their skillsets are highly interdependent with the tools at their disposal.</p>
<p>For R and python, the size of datasets becomes a limiting factor to local processing; for a SQL-focused analyst, the existence of a database is prerequisite, as the gap between “democratized” SQL <em>querying</em> skills and data engineering and database management skills is not insignificant. The ever-increasing number of managed cloud services (from data warehouses, containers, hosted IDEs and notebooks) offer a trendy and effective solution. However, budget constraints, technical know-how, security concerns, or tight-timelines can all be headwinds to adoption.</p>
<p>So what’s an analyst to do when they have the knowledge and tools but not the infrastructure to tackle their problem?</p>
<p><a href="https://DuckDB.org/"><code>DuckDB</code></a> is quickly gaining popularity as a solution to some of these problems. DuckDB is a no-dependency, serverless database management system that can help parse massive amounts of data out-of-memory via familiar SQL, python, and R APIs. Key features include:</p>
<ul>
<li><strong>Easy set-up</strong>: Easily installed as an executable or embedded within R or python packages</li>
<li><strong>Columnar storage</strong>: For efficient retrieval and vectorized computation in analytics settings</li>
<li><strong>No installation or infrastructure required</strong>: Runs seamlessly on a local machine launched from an executable</li>
<li><strong>No loading required</strong>: Can read external CSV and Parquet files <em>and</em> can smartly exploit Hive-partitioned Parquet datasets in optimization</li>
<li><strong>Expressive SQL</strong>: Provides semantic sugar for analytical SQL uses with clauses like <code>except</code> and <code>group by all</code> (see blog <a href="https://DuckDB.org/2022/05/04/friendlier-sql.html">here</a>)</li>
</ul>
<p>This combination of features can empower analysts to use what they have and what they know to ease into the processing of much larger datasets.</p>
<p>In this post, I’ll walk through a scrappy, minimum-viable setup for analysts using <code>DuckDB</code>, motivated by the <a href="https://www.ncsbe.gov/results-data">North Carolina State Board of Election</a>’s rich voter data. Those interested can follow along in <a href="https://github.com/emilyriederer/nc-votes-DuckDB">this repo</a> and put it to the test by launching a free 8GB RAM GitHub Codespaces.</p>
<p>This is very much <em>not</em> a demonstration of best practices of anything. It’s also not a technical benchmarking of the speed and capabilities of <code>DuckDB</code> versus alternatives. (That ground is well-trod. If interested, see <a href="https://DuckDB.org/2021/05/14/sql-on-pandas.html">a head-to-head to pandas</a> or <a href="https://benchmark.clickhouse.com/">a matrix of comparisons across database alternatives</a>.) If anything, it is perhaps a “user experience benchmark”, or a description of a minimum-viable set-up to help analysts use what they know to do what they need to do.</p>
<section id="motivation-north-carolina-election-data" class="level2">
<h2 class="anchored" data-anchor-id="motivation-north-carolina-election-data">Motivation: North Carolina election data</h2>
<p>North Carolina (which began accepting ballots in early September for the upcoming November midterm elections) offers a rich collection of voter data, including daily-updating information on the current election, full voter registration data, and ten years of voting history.</p>
<ul>
<li>NC 2022 midterm early vote data from <a href="https://www.ncsbe.gov/results-data">NCSBE</a> (~6K records as-of 9/23 and growing fast!)</li>
<li>NC voter registration file from <a href="https://www.ncsbe.gov/results-data">NCSBE</a> (~9M records / 3.7G unzipped, will be static for this cycle once registration closes in October)</li>
<li>NC 10-year voter history file from <a href="https://www.ncsbe.gov/results-data">NCSBE</a> (~22M records / 5G unzipped, static)</li>
</ul>
<p>All of these files are released as zipped full-population (as opposed to delta) CSV files.</p>
<p>One can imagine that this data is of great interest to campaign staff, political scientists, pollsters, and run-of-the-mill political junkies and prognosticators. However, the file sizes of registration and history data, which is critical for predicting turnout and detecting divergent trends, could be prohibitive.</p>
<p>Beyond these files, analysis using this data could surely be enriched by additional third-party sources such as:</p>
<ul>
<li>Current Population Survey 2022 November voting supplement from <a href="https://www.census.gov/data/datasets/time-series/demo/cps/cps-supp_cps-repwgt/cps-voting.html">US Census Bureau</a></li>
<li>County-level past election results from <a href="https://dataverse.harvard.edu/file.xhtml?fileId=6104822&amp;version=10.0">MIT Election Lab via Harvard Dataverse</a></li>
<li>Countless other data sources either from the US Census, public or internal campaign polls, organization-specific mobilizaton efforts, etc.</li>
</ul>
<p>Your mileage may vary based on your system RAM, but many run-of-the-mill consumer laptops might struggle to let R or python load all of this data into memory. Or, a SQL-focused analyst might yearn for a database to handle all these complex joins.</p>
<p>So how can <code>DuckDB</code> assist?</p>
</section>
<section id="duckdb-highlights" class="level2">
<h2 class="anchored" data-anchor-id="duckdb-highlights">DuckDB highlights</h2>
<p>To explain, we’ll first level-set with a brief demo of some of the most relevant features of <code>DuckDB</code>.</p>
<p>Suppose we have flat files of data, like a <code>sample.csv</code> (just many orders of magnitude larger!)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'c'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>]})</span>
<span id="cb1-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">df.to_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sample.csv'</span>, index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
</div>
<p><code>DuckDB</code> can directly infer it’s schema and read it in a SQL-like interface by using functions like <code>read_csv_auto()</code> in the <code>FROM</code> clause.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="cb4-2">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>()</span>
<span id="cb4-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"select * from read_csv_auto('sample.csv')"</span>).fetchdf()</span>
<span id="cb4-4">df.head()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">con.close()</span></code></pre></div>
</div>
<p>While very useful, this is of course bulky to type. We may also set-up a persistent DuckDB database as a <code>.duckdb</code> file as save tables with CTAS statements, as with any normal relational database. Below, we create the <code>sample-db.duckdb</code> database and add one table and one view with our data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sample-db.duckdb'</span>)</span>
<span id="cb7-2">ctas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"create or replace table sample as (select * from read_csv_auto('sample.csv'));"</span></span>
<span id="cb7-3">con.execute(ctas)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;duckdb.DuckDBPyConnection object at 0x0000000030026F70&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">cvas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"create or replace view sample_vw as (select * from read_csv_auto('sample.csv'));"</span> </span>
<span id="cb9-2">con.execute(cvas)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;duckdb.DuckDBPyConnection object at 0x0000000030026F70&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">con.close()</span></code></pre></div>
</div>
<p>Now, suppose the data in <code>sample.csv</code> changes (now with 4 rows versus 3).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'c'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>]})</span>
<span id="cb12-2">df.to_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sample.csv'</span>, index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
</div>
<p>Our table stored the data directly within the database (“disconnected” from the file) so it remains the same as before whereas our view changed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sample-db.duckdb'</span>)</span>
<span id="cb13-2">df1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"select count(1) from sample"</span>).fetchdf()</span>
<span id="cb13-3">df2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"select count(1) from sample_vw"</span>).fetchdf()</span>
<span id="cb13-4">con.close()</span>
<span id="cb13-5">df1.head()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   count(1)
0         3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df2.head()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   count(1)
0         4</code></pre>
</div>
</div>
<p>(Here, I focus just on the features we will use; not strictly the coolest or most important. I highly encourage taking a spin through the <a href="https://duckdb.org/docs/guides/python/sql_on_pandas">docs</a> for countless features not discussed – like directly querying from or fetching to pandas and Arrow formats, an alternative relational API, etc.)</p>
</section>
<section id="data-management-pattern" class="level2">
<h2 class="anchored" data-anchor-id="data-management-pattern">Data management pattern</h2>
<p>With these features in mind, we return to the problem at hand. How can an analyst mimic the experience of having the infrastructure needed to do their work?</p>
<p>One approach could look something like the following. As a one-time exercise someone would:</p>
<ol type="1">
<li>Download all relevant files</li>
<li>(Optionally) Convert large, static files to Parquet versus CSV. DuckDB handles both well, but Parquet has some benefits that we’ll discuss in the next section</li>
<li>Create a DuckDB database with references to the files as <code>view</code>s</li>
</ol>
<p>Then, any analyst wanting to interact with the data could:</p>
<ol type="1">
<li>Interact with DuckDB as with any database connection</li>
<li>Whenever needed, re-download the files to the same name/directory to “refresh” the “database”</li>
</ol>
<p>The <a href="https://github.com/emilyriederer/nc-votes-duckdb">nc-votes-duckdb</a> GitHub repo shows this flow in practice. If you want to follow along, you can click <code>Code &gt; Create codespaces on master</code> and follow the more detailed instructions in the <code>README.md</code> or at the bottom of this post.</p>
<section id="one-time-set-up" class="level3">
<h3 class="anchored" data-anchor-id="one-time-set-up">One-time set-up</h3>
<p>The scripts for the first set of steps are in the <code>etl</code> subdirectory. The e-step (extract) isn’t all that interesting – just some basic python scripts for downloading files from the internet, unzipping, and moving them around. These land the raw data in the <code>data/raw</code> subdirectory.</p>
<p>Data transformation mostly involves converting large CSVs to Parquet format (and dropping personally-identifying fields from the data on principle). As mentioned above, this step is optional but has some benefits. First, if one person is “configuring” a database for many analysts, Parquet compression makes files smaller for storage and sharing. Second, at query-time Parquet is:</p>
<ul>
<li>More reliably structured with a well-defined schema</li>
<li>Faster to retrieve due to columnar storage</li>
<li>Able to be pruned by a savvy database optimizer (when appropriately partitioned by columns relevant to common query patterns)</li>
</ul>
<p><a href="https://duckdb.org/docs/guides/import/parquet_export">Conversion from CSV to Parquet</a> itself can be done with DuckDB. However, as of writing, I don’t believe that writing to a Hive-partitioned dataset is possible, so for this step, I used <code>pyarrow</code>, the python interface to <a href="https://arrow.apache.org/">Apache Arrow</a> (another promising, memory-conserving data processing framework.)</p>
<p>This snippet from <a href="https://raw.githubusercontent.com/emilyriederer/nc-votes-duckdb/master/etl/transform-register.py">etl/transform-register.py</a> demonstrates streaming a CSV by chunk and writing it out to county-level partitions:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># convert to hive-partitioned parquet</span></span>
<span id="cb17-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> os.path.exists(path_temp):</span>
<span id="cb17-3">    shutil.rmtree(path_temp)</span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> csv.open_csv(path_raw, </span>
<span id="cb17-6">                  convert_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> opts_convr_reg, </span>
<span id="cb17-7">                  parse_options <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> opts_parse,</span>
<span id="cb17-8">                  read_options <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> opts_read_reg) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> reader:</span>
<span id="cb17-9"></span>
<span id="cb17-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> next_chunk <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> reader:</span>
<span id="cb17-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> next_chunk <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb17-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span>
<span id="cb17-13">        tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pa.Table.from_batches([next_chunk])</span>
<span id="cb17-14">        pq.write_to_dataset(</span>
<span id="cb17-15">                tbl,</span>
<span id="cb17-16">                root_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> path_temp,</span>
<span id="cb17-17">                use_dictionary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cols_reg_dict,</span>
<span id="cb17-18">                partition_cols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'county_id'</span>]</span>
<span id="cb17-19">        )</span></code></pre></div>
</div>
<p>(Notably: counties are rather imbalanced in size and not the most important geography in many election contexts. This is for example purpose only, but partitions should always be picked based on how you expect to use the data. )</p>
<p>Once all the data in transformed, we can “load” our DuckDB database with relative-path references to our data. Again, this step can be done through any DuckDB API or the command line. Below, I use python in the <a href="https://github.com/emilyriederer/nc-votes-duckdb/blob/master/etl/load-db.py">etl/load-db.py</a> to create the <code>nc.duckdb</code> database and create references to the different datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># clean-up if already exists</span></span>
<span id="cb18-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> os.path.exists(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nc.duckdb'</span>):</span>
<span id="cb18-6">  os.remove(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nc.duckdb'</span>)</span>
<span id="cb18-7"></span>
<span id="cb18-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create new duckdb files </span></span>
<span id="cb18-9">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nc.duckdb'</span>)</span>
<span id="cb18-10"></span>
<span id="cb18-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># generate SQL to register tables</span></span>
<span id="cb18-12">template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb18-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  CREATE VIEW </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{view_name}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> as </span></span>
<span id="cb18-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  (select * from read_parquet('</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{path}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{opts}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">))</span></span>
<span id="cb18-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  """</span></span>
<span id="cb18-16">data_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb18-17">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'early_vote'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data/early_vt.parquet'</span>,</span>
<span id="cb18-18">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hist_gen'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data/history_general/*/*.parquet'</span>,</span>
<span id="cb18-19">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hist_oth'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data/history_other/*/*.parquet'</span>,</span>
<span id="cb18-20">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'register'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data/register/*/*.parquet'</span>,</span>
<span id="cb18-21">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cps_suppl'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data/cps_suppl.parquet'</span></span>
<span id="cb18-22">}</span>
<span id="cb18-23">partitioned <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hist_gen'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hist_pri'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'register'</span>]</span>
<span id="cb18-24"></span>
<span id="cb18-25"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> k,v <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> data_dict.items():</span>
<span id="cb18-26"></span>
<span id="cb18-27">  <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Loading </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{view_name}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> data..."</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(view_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k))</span>
<span id="cb18-28">  opt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">', HIVE_PARTITIONING=1'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> partitioned <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span></span>
<span id="cb18-29">  cvas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> template.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(view_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k, path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> v, opts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> opt)</span>
<span id="cb18-30">  con.execute(cvas)</span>
<span id="cb18-31"></span>
<span id="cb18-32">con.close()</span></code></pre></div>
</div>
<p>Similarly, other views could be defined as desired that query these views to do further data transformation.</p>
</section>
<section id="ongoing-usage" class="level3">
<h3 class="anchored" data-anchor-id="ongoing-usage">Ongoing usage</h3>
<p>Due to the decoupling of storage and compute, ongoing data management is nearly trivial. With this “infrastructure” set-up, analysts would need only to selectively redownload any changed datasets (in my project, using the <code>extract-.*.py</code> scripts as needed) to allow their queries to pull in the latest data.</p>
<p>Big picture, that means that (after initial set-up) an analyst would have no more overhead “managing their database” than they would with a “typical” CSV-driven workflow. Specifically for this project, the early votes data is the only dataset that changes frequently. For ease-of-use, it could even be left in CSV format to make the download process even easier for any users.</p>
</section>
</section>
<section id="data-access-patterns" class="level2">
<h2 class="anchored" data-anchor-id="data-access-patterns">Data access patterns</h2>
<p>With this set-up in place, analysts can then use their favorite tools to query the data.</p>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">python</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> duckdb</span>
<span id="cb19-2">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> duckdb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nc.duckdb'</span>)</span>
<span id="cb19-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'select count(1) from early_vote'</span>).fetchdf()</span>
<span id="cb19-4">con.close()</span></code></pre></div>
</div>
</section>
<section id="r" class="level3">
<h3 class="anchored" data-anchor-id="r">R</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(duckdb)</span>
<span id="cb20-2">con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>( <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">duckdb</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nc.duckdb'</span>) )</span>
<span id="cb20-3">df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbGetQuery</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'select count(1) from early_vote'</span>)</span>
<span id="cb20-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbDisconnect</span>(con, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">shutdown =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</div>
</section>
<section id="cli" class="level3">
<h3 class="anchored" data-anchor-id="cli">CLI</h3>
<pre><code>duckdb my-db.duckdb
&gt; select count(1) from early_vote</code></pre>
</section>
<section id="sql-ide-dbeaver" class="level3">
<h3 class="anchored" data-anchor-id="sql-ide-dbeaver">SQL IDE (DBeaver)</h3>
<p>DuckDB also works with open-source database IDEs like <a href="https://dbeaver.com/">DBeaver</a> for the full, “traditional” database experience. The <a href="https://duckdb.org/docs/guides/sql_editors/dbeaver">DuckDB website</a> gives full set-up instructions. With DBeaver, analysts get the “full” database experience with navigable access to table schemas and metadata.</p>
<p><img src="https://emilyriederer.com/post/duckdb-carolina/dbeaver-query.png" class="img-fluid"></p>
<p><img src="https://emilyriederer.com/post/duckdb-carolina/dbeaver-er.png" class="img-fluid"></p>
<p>Notably <strong>if you are using relative file paths in your view definitions, you have to launch DBeaver from your command line after moving into the appropriate working directory</strong>. (Thanks to <a href="https://twitter.com/Mause_me/status/1571126401482510336?s=20&amp;t=uYOnuHSjZcjkrbwYb0aXvA">Elliana May on Twitter</a> for the pointer.) (In the terminal: <code>cd my/dir/path; dbeaver</code>)</p>
</section>
</section>
<section id="codespaces-demo" class="level2">
<h2 class="anchored" data-anchor-id="codespaces-demo">Codespaces Demo</h2>
<p>So can DuckDB help analysts wrangle the whole state of North Carolina with 8GB RAM? To find out, launch a GitHub Codespaces from the <a href="https://github.com/emilyriederer/nc-votes-duckdb">nc-votes-duckdb</a> repo and see for yourself!</p>
<ol type="1">
<li><p>Launch on Codespaces</p></li>
<li><p>Set-up environment:</p></li>
</ol>
<pre><code>python3 -m venv venv
source venv/bin/activate
python3 -m pip install -r requirements.txt</code></pre>
<ol start="3" type="1">
<li>Pull all raw data:</li>
</ol>
<pre><code>chmod +x etl/extract-all.sh
etl/extract-all.sh</code></pre>
<ol start="4" type="1">
<li>Transform all raw data:</li>
</ol>
<pre><code>chmod +x etl/transform-all.sh
etl/transform-all.sh</code></pre>
<ol start="5" type="1">
<li>Create duckdb database:</li>
</ol>
<pre><code>python etl/load-db.py</code></pre>
<ol start="6" type="1">
<li>(Optional) Install duckdb CLI</li>
</ol>
<pre><code>chmod +x get-duckdb-cli.sh
./get-duckdb-cli.sh</code></pre>
<ol start="7" type="1">
<li>Run sample queries</li>
</ol>
<p>7a. Run sample queries in CLI</p>
<p>Launch the CLI:</p>
<pre><code>./duckdb nc.duckdb
.timer on</code></pre>
<p>(Note: you can exit CLI with Ctrl+D)</p>
<p>Try out some sample queries. For example, we might wonder how many past general elections that early voters have voted in before:</p>
<pre><code>with voter_general as (
select early_vote.ncid, count(1) as n
from 
  early_vote 
  left join 
  hist_gen 
  on early_vote.ncid = hist_gen.ncid 
group by 1)
select n, count(1) as freq
from voter_general
group by 1
order by 1
;</code></pre>
<p>And, this question is more interesting if we join on registration data to learn how many prior general elections each voter was eligible to vote in:</p>
<pre><code>with voter_general as (
select 
  early_vote.ncid, 
  extract('year' from register.registr_dt) as register_year, 
  count(1) as n
from 
  early_vote 
  left join 
  hist_gen 
  on early_vote.ncid = hist_gen.ncid 
  left join
  register
  on early_vote.ncid = register.ncid
group by 1,2)
select
  n, 
  case 
  when register_year &lt; 2012 then 'Pre-2012'
  else register_year
  end as register_year,
  count(1) as freq
from voter_general
group by 1,2
order by 1,2
;</code></pre>
<p>(Yes, of course <em>date</em> matters more than year here, etc. etc. This is purely to demonstrate <code>duckdb</code> not rigorous analysis!)</p>
<p>7b. Run sample queries in python</p>
<p>In python: See sample queries in <code>test-query.py</code> file</p>
<ol start="8" type="1">
<li>Run <code>free</code> in the terminal to marvel at what 8GB of RAM can do!</li>
</ol>


</section>

 ]]></description>
  <category>data</category>
  <category>sql</category>
  <guid>https://emilyriederer.com/post/duckdb-carolina/</guid>
  <pubDate>Sun, 25 Sep 2022 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/duckdb-carolina/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Oh, I’m sure it’s probably nothing</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/nulls-polyglot/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/nulls-polyglot/featured.jpg" class="img-fluid figure-img"></p>
<figcaption>Photo credit to <a href="https://unsplash.com/@davideragusa">Davide Ragusa</a> on Unsplash</figcaption>
</figure>
</div>
<p>Language interoperability and different ways of enabling “polyglot” workflows have seemed to take centerstage in the data world recently:</p>
<ul>
<li><a href="https://arrow.apache.org/">Apache Arrow</a> promises a language-independent memory format for interoperability, - <a href="https://www.rstudio.com/blog/rstudio-is-becoming-posit/">RStudio</a> its rebranding as Posit to cement their place as a leader in language-agnostic data tooling,</li>
<li>RStudio simultaneously announced <a href="https://quarto.org/">Quarto</a> as an interoperable alternative to RMarkdown which will treat python, Julia, and JS as first-class citizens</li>
<li>dbt has released its beta of <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/python-models">python models</a> to extend is previously SQL-focused paradigm</li>
</ul>
<p>As a general matter, these are all exciting advances with great potential to aid in different workflows <em>when used judiciously</em>. However, it also poses the question: what cognitive burdens do we alleviate and which do we add when our projects begin to leverage multiple languages?</p>
<p>Despite common data analysis tools like SQL, R, and python being high-level languages with declarative interfaces (in the case of R’s <code>tidyverse</code> and python’s <code>pandas</code>), successful usage still requires understanding the underlying assumptions and operations of each tool. There is not such thing as a truly declarative language; only those that generally make decisions that the user likes well-enough to ask for the “what” and delegate the “how”. These differences can emerge at many different levels: such as foundational issues like whether data structures are copied or modified in-place or broader design choices like default hyperparameters in machine learning libraries (e.g.&nbsp;python’s <code>scikitlearn</code> notoriously uses regularized logistic regression as the default for logistic regression.) Somewhere along that spectrum lies the fickle issue of handling null values.</p>
<p>In this post, I recap a quick case study of how incautious null handling risks data analysis validity. Then, taking a step back, I compare how R, python, and SQL behave differently when confront with null values and the implications for analysts switching between languages.</p>
<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TLDR</h2>
<p>A summary of these different behaviors is provided below:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>R</strong></th>
<th style="text-align: center;"><strong>python</strong></th>
<th style="text-align: center;"><strong>SQL</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>Column Aggregation</em></td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">np: NA<br>pd: Value</td>
<td style="text-align: center;">Value</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>Row-wise Transformation</em></td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><em>Joining</em></td>
<td style="text-align: center;">Match by default</td>
<td style="text-align: center;">Match</td>
<td style="text-align: center;">No match</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>Filtering</em></td>
<td style="text-align: center;">No match</td>
<td style="text-align: center;">Match</td>
<td style="text-align: center;">No match</td>
</tr>
</tbody>
</table>
</section>
<section id="case-study" class="level2">
<h2 class="anchored" data-anchor-id="case-study">Case Study</h2>
<p>Before comparing different languages, let’s walk through a brief case study to see all the way that “lurking” nulls can surprise a junior analyst in any one language and observe a few different “contours” of the problem space.</p>
<p>Consider two tables in a retailer’s database. The <code>spend</code> table reports total sales by month and store identifier (null if online).</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  STORE_ID MONTH AMT_SPEND
1        1     1 100.12011
2        2     1 100.31441
3       NA     1 100.40517
4        1     2  99.67098
5        2     2  98.39703
6       NA     2  98.81231
7        1     3 102.27124
8        2     3 100.20843
9       NA     3        NA</code></pre>
</div>
</div>
<p>Similarly, the <code>returns</code> table reports returned sales at the same grain.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  STORE_ID MONTH AMT_RETURN
1        1     1         NA
2        2     1   9.972159
3       NA     1  10.071639
4        1     2   9.798444
5        2     2  10.254347
6       NA     2   9.881071
7        1     3  10.108880
8        2     3   9.951398
9       NA     3   9.849277</code></pre>
</div>
</div>
<p>In both cases, nulls are used in the <code>'AMT_*'</code> fields to denote zeros for the respective <code>month x store_id</code> combinations`.</p>
<p>To calculate something as simple as the average gross spend per store across months, an analyst might attempt to write:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> </span>
<span id="cb3-2">  store_id, </span>
<span id="cb3-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">avg</span>(amt_spend)</span>
<span id="cb3-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> spend</span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">group</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">order</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">store_id</th>
<th style="text-align: right;">avg(amt_spend)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">99.60874</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.68744</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">99.63996</td>
</tr>
</tbody>
</table>
</div>
<p>However, because SQL silently drops nulls in column aggregations, the online spend is not appropriately “penalized” for its lack of March spend. The averages across all three stores look nearly equal.</p>
<p>Not only is this answer “wrong”, it can also be thought of as fundamentally changing the <strong>computand</strong> (a word I just made up. In statistics, we talk about estimands as “the conceptual thing we are trying to estimate with an estimator”. Here, we aren’t estimating anything – just computing. But, there’s still a concentual “thing we are trying to measure” and in this case, it’s our <em>tools</em> and not our <em>methods</em> that are imposing assumptions on that) to one that answers a fundamentally different question:</p>
<p>Instead of measuring “average monthly spend in Q1 by store”, we’re measuring “averaging monthly spend in Q1 by store <em>conditional on</em> there being spend”.</p>
<p>To obtain the correct result, one would write:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> </span>
<span id="cb4-2">  store_id, </span>
<span id="cb4-3">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-- wrong answers</span></span>
<span id="cb4-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">avg</span>(amt_spend) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> wrong1,  </span>
<span id="cb4-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(amt_spend) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">count</span>(amt_spend) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> wrong2,</span>
<span id="cb4-6">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-- right answers</span></span>
<span id="cb4-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(amt_spend) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">count</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> right1,</span>
<span id="cb4-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">avg</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(amt_spend, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> right2</span>
<span id="cb4-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> spend</span>
<span id="cb4-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">group</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">order</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">store_id</th>
<th style="text-align: right;">wrong1</th>
<th style="text-align: right;">wrong2</th>
<th style="text-align: right;">right1</th>
<th style="text-align: right;">right2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">99.60874</td>
<td style="text-align: right;">99.60874</td>
<td style="text-align: right;">66.40583</td>
<td style="text-align: right;">66.40583</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.68744</td>
<td style="text-align: right;">100.68744</td>
<td style="text-align: right;">100.68744</td>
<td style="text-align: right;">100.68744</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">99.63996</td>
<td style="text-align: right;">99.63996</td>
<td style="text-align: right;">99.63996</td>
<td style="text-align: right;">99.63996</td>
</tr>
</tbody>
</table>
</div>
<p>With a better understand of gross sales, the analyst might next proceed to compute net sales.</p>
<p>This first requires joining the <code>spend</code> and <code>returns</code> tables. Naively, they might attempt:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> </span>
<span id="cb5-2">  spend.<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>,</span>
<span id="cb5-3">  returns.amt_return</span>
<span id="cb5-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb5-5">  spend</span>
<span id="cb5-6">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span></span>
<span id="cb5-7">  returns </span>
<span id="cb5-8">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span></span>
<span id="cb5-9">  spend.store_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.store_id <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span></span>
<span id="cb5-10">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">STORE_ID</th>
<th style="text-align: right;">MONTH</th>
<th style="text-align: right;">AMT_SPEND</th>
<th style="text-align: right;">amt_return</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.12011</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.31441</td>
<td style="text-align: right;">9.972159</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">99.67098</td>
<td style="text-align: right;">9.798444</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">98.39703</td>
<td style="text-align: right;">10.254347</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">102.27124</td>
<td style="text-align: right;">10.108880</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">100.20843</td>
<td style="text-align: right;">9.951398</td>
</tr>
</tbody>
</table>
</div>
<p>However, this once again fails. Why? Although SQL handled nulls “permissively” when aggregating a column, it took a stricted stance when making the comparison on <code>spend.store_id = returns.store_id</code> in the join clause. SQL doesn’t recognize different nulls as equal. To the extent than null means “I dunno” versus “The field is not relevant to this observation”, it’s reasonable that SQL should find it hard to decide whether two “I dunno”s are equal.</p>
<p>Once again, this isn’t a “random” or inconsequential error. Continuing to use this corrupted dataset changes the computand from “net sales by month” to “net sales by month at physical retail locations”.</p>
<p>To remedy this, we can force <code>store_id</code> to take on a value:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span></span>
<span id="cb6-2">  spend.<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>,</span>
<span id="cb6-3">  returns.amt_return</span>
<span id="cb6-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb6-5">  spend</span>
<span id="cb6-6">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span></span>
<span id="cb6-7">  returns </span>
<span id="cb6-8">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span></span>
<span id="cb6-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(spend.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(returns.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span></span>
<span id="cb6-10">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">STORE_ID</th>
<th style="text-align: right;">MONTH</th>
<th style="text-align: right;">AMT_SPEND</th>
<th style="text-align: right;">amt_return</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.12011</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.31441</td>
<td style="text-align: right;">9.972159</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.40517</td>
<td style="text-align: right;">10.071639</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">99.67098</td>
<td style="text-align: right;">9.798444</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">98.39703</td>
<td style="text-align: right;">10.254347</td>
</tr>
<tr class="even">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">98.81231</td>
<td style="text-align: right;">9.881071</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">102.27124</td>
<td style="text-align: right;">10.108880</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">100.20843</td>
<td style="text-align: right;">9.951398</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">9.849277</td>
</tr>
</tbody>
</table>
</div>
<p>And next we proceed with computing sales by month net of returns across all stores:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span></span>
<span id="cb7-2">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span>, </span>
<span id="cb7-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(amt_spend <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> amt_return) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> net_spend</span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb7-5">  spend</span>
<span id="cb7-6">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span></span>
<span id="cb7-7">  returns </span>
<span id="cb7-8">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span></span>
<span id="cb7-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(spend.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(returns.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span></span>
<span id="cb7-10">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span></span>
<span id="cb7-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">group</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">order</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">month</th>
<th style="text-align: right;">net_spend</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">180.6758</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">266.9465</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">182.4194</td>
</tr>
</tbody>
</table>
</div>
<p>However, by now, you should not be surprised that this result is also incorrect. If we inspect the sequence of computations, we realize that SQL is also stricter in its null handing in <em>rowwise computations</em> than <em>column-wise aggregations</em>. The subtraction of <code>amt_spend</code> and <code>amt_return</code> obliterates the total when either is null. So, we fail to include the gross spend at Store 1 in January simply because there were no returns (and vice versa for Internet sales in March).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span></span>
<span id="cb8-2">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span>, </span>
<span id="cb8-3">  spend.store_id,</span>
<span id="cb8-4">  amt_spend,</span>
<span id="cb8-5">  amt_return,</span>
<span id="cb8-6">  amt_spend <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> amt_return <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> net_spend</span>
<span id="cb8-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb8-8">  spend</span>
<span id="cb8-9">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span></span>
<span id="cb8-10">  returns </span>
<span id="cb8-11">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span></span>
<span id="cb8-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(spend.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(returns.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span></span>
<span id="cb8-13">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">month</th>
<th style="text-align: right;">store_id</th>
<th style="text-align: right;">amt_spend</th>
<th style="text-align: right;">amt_return</th>
<th style="text-align: right;">net_spend</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">100.12011</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">100.31441</td>
<td style="text-align: right;">9.972159</td>
<td style="text-align: right;">90.34225</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">100.40517</td>
<td style="text-align: right;">10.071639</td>
<td style="text-align: right;">90.33353</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">99.67098</td>
<td style="text-align: right;">9.798444</td>
<td style="text-align: right;">89.87254</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">98.39703</td>
<td style="text-align: right;">10.254347</td>
<td style="text-align: right;">88.14268</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">98.81231</td>
<td style="text-align: right;">9.881071</td>
<td style="text-align: right;">88.93124</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">102.27124</td>
<td style="text-align: right;">10.108880</td>
<td style="text-align: right;">92.16236</td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">100.20843</td>
<td style="text-align: right;">9.951398</td>
<td style="text-align: right;">90.25704</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">9.849277</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
<p>A few ways to get the correct answer are shown below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span></span>
<span id="cb9-2">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span>, </span>
<span id="cb9-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(amt_spend,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(amt_return,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> right1,</span>
<span id="cb9-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(amt_spend) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(amt_return) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> right2</span>
<span id="cb9-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb9-6">  spend</span>
<span id="cb9-7">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span></span>
<span id="cb9-8">  returns </span>
<span id="cb9-9">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span></span>
<span id="cb9-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(spend.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coalesce</span>(returns.store_id, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span></span>
<span id="cb9-11">  spend.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> returns.<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span></span>
<span id="cb9-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">group</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb9-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">order</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">by</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">month</th>
<th style="text-align: right;">right1</th>
<th style="text-align: right;">right2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">280.7959</td>
<td style="text-align: right;">280.7959</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">266.9465</td>
<td style="text-align: right;">266.9465</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">172.5701</td>
<td style="text-align: right;">172.5701</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="observations" class="level2">
<h2 class="anchored" data-anchor-id="observations">Observations</h2>
<p>The preceding example hopefully illustrates a few points:</p>
<ul>
<li>Nulls can cause issues in the most basic of analyses</li>
<li>Beyond causing random or marginal errors, null handling changes the questions being answered</li>
<li>Even within a language, null handling may feel inconsistent (w.r.t. strictness) across different operations</li>
</ul>
<p>So, with that, let’s compare languages!</p>
</section>
<section id="comparison" class="level2">
<h2 class="anchored" data-anchor-id="comparison">Comparison</h2>
<p>Below, we compare how R, SQL, and python handle column aggregation, rowwise transformation, joining, and filtering.</p>
<section id="aggregation" class="level3">
<h3 class="anchored" data-anchor-id="aggregation">Aggregation</h3>
<p>SQL, as we saw before, simply ignores nulls in aggregation functions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> </span>
<span id="cb10-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(x) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> sum_x, </span>
<span id="cb10-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span>(x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> n_null_x</span>
<span id="cb10-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> tbl</span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">sum_x</th>
<th style="text-align: right;">n_null_x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
<p>Built by and for statistician’s, R is scandalized at the very idea of attempting to do math with null columns. For aggregation functions, it returns <code>NA</code> as a form of protest should any entry of the vector provided be null. (This can be overridden with the <code>na.rm</code> parameter.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1">x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>)</span>
<span id="cb11-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(x)</span>
<span id="cb11-3"></span>
<span id="cb11-4">df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x)</span>
<span id="cb11-5">dplyr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(df, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(x))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] NA</code></pre>
</div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>When it comes to python, well, it depends. Base and <code>numpy</code> operations act more like R whereas <code>pandas</code> aggregation acts more like SQL.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb13-3">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,np.nan]</span>
<span id="cb13-4">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span>
<span id="cb13-5">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>:x,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>:y})</span>
<span id="cb13-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(x)</span>
<span id="cb13-7">np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(x)</span>
<span id="cb13-8">df.agg({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sum'</span>]})</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>nan
nan
       x
sum  3.0</code></pre>
</div>
</div>
</section>
<section id="transformation" class="level3">
<h3 class="anchored" data-anchor-id="transformation">Transformation</h3>
<p>All of SQL, R, and python return NA when <code>NA</code>s are used in atomic or rowwise transformations.</p>
<p>In SQL:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">as</span> z</span>
<span id="cb15-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> tbl</span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
<th style="text-align: right;">y</th>
<th style="text-align: right;">z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
<p>In R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1">df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb16-2">dplyr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(df, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">z =</span> x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y)</span>
<span id="cb16-3"></span>
<span id="cb16-4">df<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>z <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">with</span>(df, x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y)</span>
<span id="cb16-5">df</span></code></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
<th style="text-align: right;">y</th>
<th style="text-align: right;">z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
<th style="text-align: right;">y</th>
<th style="text-align: right;">z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NA</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>In python:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">np.array(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.array(y)</span>
<span id="cb17-2">df.assign(z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> d: d.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> d.y)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([-2., -2., nan])
     x  y    z
0  1.0  3 -2.0
1  2.0  4 -2.0
2  NaN  5  NaN</code></pre>
</div>
</div>
</section>
<section id="joining" class="level3">
<h3 class="anchored" data-anchor-id="joining">Joining</h3>
<p>The situation with joins may feel like the opposite of aggregation. Here, R and python’s most popular data wrangling packages are more permissive than SQL.</p>
<p>As we saw in the case study, SQL does not match on nulls.</p>
<p>Consider <code>tbl1</code> and <code>tbl2</code> as shown below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> tbl1</span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">TRUE</td>
</tr>
</tbody>
</table>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb20-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> tbl2</span></code></pre></div>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">FALSE</td>
</tr>
</tbody>
</table>
</div>
<p>Attempts to join return no results:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> tbl1.<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>, tbl2.Y </span>
<span id="cb21-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> </span>
<span id="cb21-3">  tbl1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">inner</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">join</span> tbl2 </span>
<span id="cb21-4">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">on</span> </span>
<span id="cb21-5">  tbl1.A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tbl2.A <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> </span>
<span id="cb21-6">  tbl1.B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tbl2.B</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
<th style="text-align: left;">y</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
</div>
<p>In contrast, default behavior for base R’s <code>merge</code> and <code>dplyr</code> <em>does match</em> on nulls. (Although, either behavior can be altered with the <code>incomparables</code> or <code>na_matches</code> arguments, respectively.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1">df1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">A =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">B =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">X =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span>
<span id="cb22-2">df2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">A =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">B =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Y =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb22-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">merge</span>(df1, df2, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>))</span>
<span id="cb22-4">dplyr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inner_join</span>(df1, df2, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"B"</span>))</span></code></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
<th style="text-align: left;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">TRUE</td>
<td style="text-align: left;">FALSE</td>
</tr>
</tbody>
</table>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
<th style="text-align: left;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">TRUE</td>
<td style="text-align: left;">FALSE</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Similarly, <code>pandas</code> also matches on nulls for joining.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb23-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb23-3">df1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, np.nan, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>]], columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>])</span>
<span id="cb23-4">df2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, np.nan, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>]], columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y'</span>])</span>
<span id="cb23-5">pd.merge(df1, df2, on <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   A   B     X      Y
0  1 NaN  True  False</code></pre>
</div>
</div>
<p><code>R</code> and <code>python</code>’s behavior here seems most surprising. One might expect joining to work the same as raw logical evaluation works. However, neither language “likes” null comparison in its raw form. Instead, the default behavior is intentionally altered in these higher-level joining functions.</p>
<p>In R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] NA</code></pre>
</div>
</div>
<p>In python:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">np.nan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> np.nan</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False</code></pre>
</div>
</div>
</section>
<section id="filtering" class="level3">
<h3 class="anchored" data-anchor-id="filtering">Filtering</h3>
<p>Finally, both SQL and R drop null records used in filtering statements since comparisons with these values are incapable of returning a TRUE/FALSE value that is used to subset the rows. In python, however, pandas does preserve nulls in filter conditions.</p>
<p>Using the same <code>tbl1</code> shown above, we can also confirm that SQL proactively drops nulls in where clauses where they cannot be readily compared to non-null values. This seems quite consistent with its behavior in the joining case.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb29-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">select</span> A, B, X </span>
<span id="cb29-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">from</span> tbl1 </span>
<span id="cb29-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">where</span> B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">a</th>
<th style="text-align: left;">b</th>
<th style="text-align: left;">x</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
</div>
<p>Both base R and <code>dplyr</code> paradigms follow suit here.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1">df1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">A =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">B =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">X =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span>
<span id="cb30-2">df1[df1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>B <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,]</span>
<span id="cb30-3">dplyr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(df1, B <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">NA</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">X</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
</div>
</div>
<p>However, bucking the trend, multiple approaches to subsetting <code>pandas</code> data will not drop nulls in filtering comparisons.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">df1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, np.nan, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>]], columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>])</span>
<span id="cb31-2">df1[df1.B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb31-3">df1.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B != 1'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   A   B     X
0  1 NaN  True
   A   B     X
0  1 NaN  True</code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In data computation and analysis, the devil is often in the details. It’s not breaking news that low-level reasoning on the careful handling of null values can jeopardize the resulting analyses. However, as analysts take on increasingly complex tasks and using a plehora of different tools, it’s more important than ever for both data producers and consumers to consider the choices they are making in encoding and handling these values across the stack.</p>


</section>

 ]]></description>
  <category>rstats</category>
  <category>python</category>
  <category>sql</category>
  <category>data</category>
  <category>data-disasters</category>
  <guid>https://emilyriederer.com/post/nulls-polyglot/</guid>
  <pubDate>Mon, 05 Sep 2022 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/nulls-polyglot/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Update: grouped data quality check PR merged to dbt-utils</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/grouping-data-quality-update/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/grouping-data-quality-update/featured.jpg" class="img-fluid figure-img"></p>
<figcaption>Photo credit to <a href="https://unsplash.com/@greysonjoralemon">Greyson Joralemon</a> on Unsplash</figcaption>
</figure>
</div>
<p>Last fall, I wrote about the <a href="https://www.emilyriederer.com/post/grouping-data-quality/">unreasonably effectiveness of grouping in data quality checks</a>. In this follow-up, I want to share that my <a href="https://github.com/dbt-labs/dbt-utils/pull/633">pull request</a> for such features has just been merged into the development branch of the <code>dbt-utils</code> package, a common add-on to the <code>dbt</code> data transformation stack. This feature will officially “go live” in the 1.0.0 version release that is planned for later this fall.</p>
<p>In this brief post, I’ll recall the benefits of such checks (which my original post further illustrates with NYC subway data) and demonstrate how these checks can now be implemented in <code>dbt-utils</code>.</p>
<p>For those interested, I’ll also provide a brief overview of how I implemented this change, but I recommend checking out the PR itself for complete details.</p>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<p>To recap the benefits of such checks from my initial post:</p>
<ul>
<li>Some data checks can only be expressed within a group (e.g.&nbsp;ID values should be unique within a group but can be repeated between groups)</li>
<li>Some data checks are more precise when done by group (e.g.&nbsp;not only should table row-counts be equal but the counts within each group should be equal)</li>
</ul>
<p>Of course, these benefits are more or less relevant to different types of data checks. My PR updates the following tests:</p>
<ul>
<li>equal_rowcount()</li>
<li>recency()</li>
<li>fewer_rows_than()</li>
<li>at_least_one()</li>
<li>not_constant()</li>
<li>non_null_proportion()</li>
<li>sequential_values()</li>
</ul>
<p>Of these checks, most fall in the category of providing more rigor when being conducted at the group level. Only the <code>sequential_values()</code> test is often unable to be expressed without grouping.</p>
</section>
<section id="demo" class="level2">
<h2 class="anchored" data-anchor-id="demo">Demo</h2>
<p><a href="https://docs.getdbt.com/docs/building-a-dbt-project/tests">Data tests</a> in <code>dbt</code> are specified in the <code>schema.yml</code> file for relevant models. Adding grouping to the tests listed above will now be as simple as adding a <code>group_by_columns</code> key-value pair to the tests, as desired, which accepts either a single variable name or a list of variables to be used for grouping.</p>
<p><code>{yaml eval = FALSE}   - name: data_test_at_least_one     columns:       - name: field         tests:           - dbt_utils.at_least_one:               group_by_columns: ['grouping_column']</code></p>
<p>For those that have not used <code>dbt</code>’s data testing framework before, this configuration is then used to generate SQL (now with the custom <code>GROUP BY</code> clause) which are evaluated when <code>dbt test</code> is run.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>In implementing this PR, I considered a few core principles:</p>
<ul>
<li>Make this feature as unobtrusive and isolated as possible with respect to the macros broader implementation</li>
<li>Follow standard DRY principles (e.g.&nbsp;specifically, render needed text as few times as possible)</li>
<li>Implement consistently across macros</li>
</ul>
<p>With these principles in mind, the majority of implementations are like that of the <code>recency</code> macro where all relevant SQL strings are pre-computed:</p>
<pre><code>{% set threshold = dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp()) %}
{% if group_by_columns|length() &gt; 0 %}
  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}
  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}
{% endif %}</code></pre>
<p>The main deviations to this were the sequential() macro (requiring a window function) and the equal_rowcount()/fewer_rows_than() (requiring joins)</p>


</section>

 ]]></description>
  <category>data</category>
  <category>dbt</category>
  <guid>https://emilyriederer.com/post/grouping-data-quality-update/</guid>
  <pubDate>Fri, 26 Aug 2022 05:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/grouping-data-quality-update/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The Data Engineering Podcast: Column Names as Contracts</title>
  <link>https://emilyriederer.com/talk/pod-tdep-colnames/</link>
  <description><![CDATA[ 




<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Quick Links</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Abstract</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Listen</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p><span><i class="bi bi-play"></i> <a href="https://www.dataengineeringpodcast.com/controlled-vocabulary-with-dbtplyr-episode-252/">Pod</a> </span><br>
<span><i class="bi bi-download"></i><a href="tdep_col-name-contracts.mp3">Download MP3</a></span><br>
<span><i class="bi bi-pencil"></i> <a href="../..\post/column-name-contracts/">Post - Column Names as Contracts</a> </span></p>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<p>Communication and shared context are the hardest part of any data system. In recent years the focus has been on data catalogs as the means for documenting data assets, but those introduce a secondary system of record in order to find the necessary information. In this episode Emily Riederer shares her work to create a controlled vocabulary for managing the semantic elements of the data managed by her team and encoding it in the schema definitions in her data warehouse. She also explains how she created the dbtplyr package to simplify the work of creating and enforcing your own controlled vocabularies.</p>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<iframe src="https://player.fireside.fm/v2/fE6B9ALy+6SCH5nMW?theme=dark" width="740" height="200" frameborder="0" scrolling="no">
</iframe>
</div>
</div>
</div>



 ]]></description>
  <category>data</category>
  <guid>https://emilyriederer.com/talk/pod-tdep-colnames/</guid>
  <pubDate>Wed, 12 Jan 2022 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/talk/pod-tdep-colnames/featured.PNG" medium="image"/>
</item>
<item>
  <title>Using databases with Shiny</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/shiny-db/</link>
  <description><![CDATA[ 





<p>Shiny apps are R’s answer to building interface-driven applications that help expose important data, metrics, algorithms, and more with end-users. However, the more interesting work that your Shiny app allows users to do, the more likely users are to want to save, return to, and alter some of the ways that they interacted with your work.</p>
<p>This creates a need for <strong>persistent storage</strong> in your Shiny application, as opposed to the ephemeral in-memory of basic Shiny applications that “forget” the data that they generated as soon as the application is stopped.</p>
<p>Relational databases are a classic form of persistent storage for web applications. Many analysts may be familiar with <em>querying</em> relational databases to retrieve data, but <em>managing</em> a database for use with a web application is slightly more complex. You’ll find yourself needing to define tables, secure data, and manage connections. More importantly, you might worry about what things that you do not know you should be worrying about.</p>
<p>This post provides some tips, call-outs, and solutions for using a relational database for persistent storage with Shiny. In my case, I rely on a Shiny app built with the <a href="https://thinkr-open.github.io/golem/"><code>golem</code> framework</a> and served on the Digital Ocean App platform.</p>
<section id="databases-options-for-storage" class="level2">
<h2 class="anchored" data-anchor-id="databases-options-for-storage">Databases &amp; Options for Storage</h2>
<p>Dean Attali’s <a href="https://deanattali.com/blog/shiny-persistent-data-storage/">blog post on persistent storage</a> compares a range of options for persistent storage including databases, S3 buckets, Google Drive, and more.</p>
<p>For my application, I anticipated the need to store and retrieve sizable amounts of structured data, so using a relational database seemed like a good option. Since I was hosting my application on <a href="https://m.do.co/c/6c5fdc198503">Digital Ocean App Platform</a>, I could create a <a href="https://www.digitalocean.com/products/managed-databases/">managed Postgres database</a> with just a few button clicks. As I share in the “Key Issues” section, this solution offers some significant benefits in terms of security.</p>
<p>For more information on different options for hosting Shiny apps and some insight into why I chose Digital Ocean, check out Peter Solymos’ excellent blog on <a href="https://hosting.analythium.io/">Hosting Data Apps</a>.</p>
</section>
<section id="talking-to-your-database-through-shiny" class="level2">
<h2 class="anchored" data-anchor-id="talking-to-your-database-through-shiny">Talking to your database through Shiny</h2>
<p>General information on working with databases with R is included on RStudio’s <a href="https://db.rstudio.com/">excellent website</a>. Below, I focus on a few topics specific to databases with Shiny, Shiny apps built in the <code>{golem}</code> framework, and Shiny apps served on Digital Ocean in particular.</p>
<section id="creating-a-database" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-database">Creating a database</h3>
<p>To create a database for my application in DigitalOcean, I simply went to:</p>
<p><code>Settings &gt; Add Component &gt; Database</code></p>
<p>This creates a fully-managed Postgres databases so you do not have to thing a ton about the underlying set-up or configuration.</p>
<p>At the time on writing, I was able to add a 1GB Dev Database for /$7 / month. For new users, DigitalOcean offers a generous number of free credits for use in the first 60 days. For a more mature product, one can add or switch to a production-ready Managed Database.</p>
<p>After a few minutes, the database has launched and its Connection Parameters are provided, which look something like this:</p>
<pre><code>host     : abc.b.db.ondigitalocean.com
port     : 25060
username : db
password : abc123
database : db
sslmode  : require</code></pre>
<p>By default, the Dev Database registers your application as a Trusted Source, meaning that only traffic from the application can attempt to access the database. As the <a href="https://docs.digitalocean.com/products/databases/postgresql/how-to/secure/#firewalls">documentation</a> explains, this type of firewall improves security by preventing against brute-force password or denial-of-service attacks from the outside.</p>
<p><em>Note: If you just want to experiment with databases and Shiny but aren’t using an in-production, served application, you can mostly skip this step and use the “Dev” approach that is discuss in “Dev versus Prod” subsection of “Key Issues” below.</em></p>
</section>
<section id="connecting-to-the-database" class="level3">
<h3 class="anchored" data-anchor-id="connecting-to-the-database">Connecting to the database</h3>
<p>We can use the connection parameters provided to connect to the database using R’s <code>DBI</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(RPostgres<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Postgres</span>(),</span>
<span id="cb2-2">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">host   =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aabc.b.db.ondigitalocean.com"</span>,</span>
<span id="cb2-3">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dbname =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb2-4">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">user      =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb2-5">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">password  =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abc123"</span>,</span>
<span id="cb2-6">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">port     =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25060</span>)</span></code></pre></div>
</div>
<p>We will talk about ways to not hardcode one’s password in the last section.</p>
</section>
<section id="creating-tables" class="level3">
<h3 class="anchored" data-anchor-id="creating-tables">Creating tables</h3>
<p>Next, you can set up tables in your database that your application will require.</p>
<p>If you know SQL DDL, you can write a <a href="https://www.tutorialspoint.com/sql_certificate/using_ddl_statements.html">CREATE TABLE statement</a> which defines a tables names, fields, and data types. However, this can feel verbose or uncomfortable to analysts who mostly use DML (e.g.&nbsp;<code>SELECT</code>, <code>FROM</code>, <code>WHERE</code>).</p>
<p>Fortunately, you can also define a table using R’s <code>DBI</code> package. First, create a simple dataframe with a single record to help R infer the appropriate and expected data types. Then pass the first <em>zero</em> rows of the table (essentially, only the schema) to <code>DBI::dbCreateTable()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">z =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2022-01-01"</span>))</span>
<span id="cb3-2">DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbCreateTable</span>(con, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_data"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fields =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">head</span>(df, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span></code></pre></div>
</div>
<p>To prove that this works, I show a “round trip” of the data using an in-memory SQLite database. Note that this is <em>not</em> an option for persistent storage because in-memory databases are not persistent. This is only to “prove” that this approach can create database tables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">con_lite <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(RSQLite<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SQLite</span>(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">":memory:"</span>)</span>
<span id="cb4-2">df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">z =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2022-01-01"</span>))</span>
<span id="cb4-3">DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbCreateTable</span>(con_lite, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_data"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fields =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">head</span>(df, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb4-4">DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbListTables</span>(con_lite)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "my_data"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbReadTable</span>(con_lite, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_data"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] x y z
&lt;0 rows&gt; (or 0-length row.names)</code></pre>
</div>
</div>
<p>But where should you run this script? You do <em>not</em> want to put this code in your app to run every time the app launches, but we just limited database traffic to the app so we cannot run it locally. Instead, you can run this code from the app’s <a href="https://docs.digitalocean.com/products/app-platform/concepts/console/">console</a>. (Alternatively, if you upgrade to a Managed Database, I believe you can also whitelist your local IP as another trusted source.)</p>
</section>
<section id="forming-the-connection-within-your-app" class="level3">
<h3 class="anchored" data-anchor-id="forming-the-connection-within-your-app">Forming the connection within your app</h3>
<p>Once your database is set-up and ready to go, you can begin to integrate it into your application.</p>
<p>I was using the <a href="https://thinkr-open.github.io/golem/"><code>golem</code> framework</a> for my application, so I connected to the database and made the initial data pull by adding the following lines in my top-level <code>app_server.R</code> file.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">db_con</span>()</span>
<span id="cb8-2">tbl_init <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbReadTable</span>(con, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_data"</span>)</span></code></pre></div>
</div>
<p>The custom <code>db_con()</code> function contains <em>roughly</em> the <code>DBI::dbConnect()</code> code we saw above, but I turned it into a function to incorporate some added complexity which I will describe shortly.</p>
<p>Most of the rest of my application uses Shiny modules, and this connection object and initial data pull can be seamless passed into either.</p>
<p>To see similar code in a full app, check out Colin Fay’s <a href="https://github.com/ColinFay/golemexamples/blob/master/golemqlite/R/app_server.R#L7"><code>golemqlite</code></a> project on Github.</p>
</section>
<section id="crud-operations" class="level3">
<h3 class="anchored" data-anchor-id="crud-operations">CRUD operations</h3>
<p>CRUD operations (Create, Read, Update, Delete) are at the heart of any interactive application with persistent data storage.</p>
<p>Interacting with your database within Shiny begins to look like more rote Shiny code. I do not describe this process in much detail since it is quite specific to what your app is trying to accomplish, but <a href="https://www.tychobra.com/posts/2020-01-29-shiny-crud-traditional/">this blog post</a> provides some nice examples.</p>
<p>In short:</p>
<ul>
<li>To add records to the table, you can use <code>DBI::dbAppendTable()</code></li>
<li>To remove records from the table, you can construct a <code>DELETE FROM my_data WHERE &lt;conditions&gt;</code> statement and run it with <code>DBI::dbExecute()</code></li>
</ul>
<p>Some cautions on the second piece are included in the “Key Issues” section.</p>
</section>
</section>
<section id="key-issues" class="level2">
<h2 class="anchored" data-anchor-id="key-issues">Key Issues</h2>
<p>Adding a permanent data store to your application can open up a lot of exciting new functionality. However, it may create some challenges that your typical data analyst or Shiny developer has not faced before. In this last section, I highlight a few key issues that you should be aware of and provide some recommendations.</p>
<section id="securing-data-transfer" class="level3">
<h3 class="anchored" data-anchor-id="securing-data-transfer">Securing data transfer</h3>
<p>Already, we have one safeguard in place for data security since our application is the only Trusted Source able to interface with our database.</p>
<p>But, just like we secure our database credentials, it becomes important to think about securing the database itself. This is made easy with DigitalOcean because data is <a href="https://docs.digitalocean.com/products/databases/">end-to-end encrypted</a>, but depending on how or by whom your data is managed, this is something to bear in mind.</p>
</section>
<section id="securing-database-credentials" class="level3">
<h3 class="anchored" data-anchor-id="securing-database-credentials">Securing database credentials</h3>
<p>No matter how safe the data itself is, it still may be at risk if anyone can obtain our database credentials.</p>
<p>Previously, I demonstrated how to connect to a database from R like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(RPostgres<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Postgres</span>(),</span>
<span id="cb9-2">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">host   =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aabc.b.db.ondigitalocean.com"</span>,</span>
<span id="cb9-3">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dbname =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb9-4">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">user      =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb9-5">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">password  =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abc123"</span>,</span>
<span id="cb9-6">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">port     =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25060</span>)</span></code></pre></div>
</div>
<p>However, you should never ever put your password in plaintext like this. Instead, you can use <em>environment variables</em> to store the value of sensitive credentials like a password or even a username like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(RPostgres<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Postgres</span>(),</span>
<span id="cb10-2">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">host   =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aabc.b.db.ondigitalocean.com"</span>,</span>
<span id="cb10-3">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dbname =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb10-4">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">user      =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb10-5">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">password  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DB_PASS"</span>),</span>
<span id="cb10-6">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">port     =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25060</span>)</span></code></pre></div>
</div>
<p>Then, you can define that same environment variable more securely in <a href="https://docs.digitalocean.com/products/app-platform/how-to/use-environment-variables/">within the App Platform</a>.</p>
</section>
<section id="securing-input-integrity-sql-injection" class="level3">
<h3 class="anchored" data-anchor-id="securing-input-integrity-sql-injection">Securing input integrity (SQL injection)</h3>
<p>Finally, it’s also important to be aware of <a href="https://www.w3schools.com/sql/sql_injection.asp">SQL injection</a> to ensure that your database does not get corrupted.</p>
<p>SQL injection is usually discussed in the concept of malicious attacks. For example, W3 schools shows the following example where an application could be tricked into providing data on <em>all</em> users instead of a single user:</p>
<pre><code>txtUserId = getRequestString("UserId");
txtSQL = "SELECT * FROM Users WHERE UserId = " + txtUserId;</code></pre>
<p>If the entered <code>UserId</code> is <code>"UserId = 105 OR 1=1"</code>, then the full SQL string will be <code>"SELECT * FROM Users WHERE UserId = 105 OR 1=1;"</code>.</p>
<p>SQL injection is also at jokes you make have heard about “little Bobby Drop Tables” (<a href="https://xkcd.com/327/">xkcd</a>).</p>
<p><img src="https://imgs.xkcd.com/comics/exploits_of_a_mom.png" class="img-fluid"></p>
<p>That joke also, in some odd way, highlights that SQL injection need not be malicious. Rather, whenever we have software opened up to users beyond ourselves, they will likely use it in unexpected ways that push the system to its limit. For example, a user might try to enter or remove values from our database with double quotes, semicolons, or other features that mean something different to SQL than in human parlance and corrupt the code. Regardless of intent, we can protect against bad SQL that will break our application by using the <code>DBI::sqlInterpolate()</code> function.</p>
<p>A demonstration of this function and how it can protect against bad query generation is shown in <a href="https://shiny.rstudio.com/articles/sql-injections.html">this post</a> by RStudio.</p>
</section>
<section id="dev-versus-prod" class="level3">
<h3 class="anchored" data-anchor-id="dev-versus-prod">Dev versus Prod</h3>
<p>However, you may have realized a flaw in this approach. Our entire app now depends on forming a connection <em>that can only be made by the in-production app.</em> This meams you cannot test your application locally. However, even if our local traffic was not categorically blocked, we wouldn’t <em>want</em> to test our app on the production database and recklessly add and remove entries.</p>
<p>Instead, we would ideally have <em>separate</em> databases: one for development and one for production. Ideally, these would be the same type of database (e.g.&nbsp;both Postgres) to catch nuances of different SQL syntax and database operations. However, to keep things simpler (and cheaper), I decided to use an in-memory SQLite database locally.</p>
<p>To accomplish this, I wrapped my database connection in a custom <code>db_con()</code> function that checks if the app is running in development or production (using <code>golem::app_prod()</code> which in turn checks the <code>R_CONFIG_ACTIVE</code> environment variable) and connects to different databases in either case. In the development case, it creates an in-memory SQLite database and remakes the empty table.</p>
<p>(Another alternative to creating the database on-the-fly is to <a href="https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html#Creating_a_new_SQLite_database">pre-make a SQLite database</a> saved to a <code>.sqlite</code> file and connect to that. But for this example, my sample table is so simple, creating it manually takes a negligible amount of time and keeps things quite readable, so I left it as-is.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">db_con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prod =</span> golem<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">app_prod</span>()) {</span>
<span id="cb12-2">  </span>
<span id="cb12-3">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (prod) {</span>
<span id="cb12-4">    </span>
<span id="cb12-5">    con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(RPostgres<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Postgres</span>(),</span>
<span id="cb12-6">                          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">host   =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abc.b.db.ondigitalocean.com"</span>,</span>
<span id="cb12-7">                          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dbname =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb12-8">                          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">user      =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"db"</span>,</span>
<span id="cb12-9">                          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">password  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DB_PASS"</span>),</span>
<span id="cb12-10">                          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">port     =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25060</span>)</span>
<span id="cb12-11">    </span>
<span id="cb12-12">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb12-13">    </span>
<span id="cb12-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stopifnot</span>( <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">require</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RSQLite"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">quietly =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) )</span>
<span id="cb12-15">    con <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbConnect</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SQLite</span>(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">":memory:"</span>)</span>
<span id="cb12-16">    df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">z =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2022-01-01"</span>))</span>
<span id="cb12-17">    DBI<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dbWriteTable</span>(con, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_data"</span>, df)</span>
<span id="cb12-18">    </span>
<span id="cb12-19">  }</span>
<span id="cb12-20">  </span>
<span id="cb12-21">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(con)</span>
<span id="cb12-22">  </span>
<span id="cb12-23">}</span></code></pre></div>
</div>
</section>
<section id="managing-connections" class="level3">
<h3 class="anchored" data-anchor-id="managing-connections">Managing connections</h3>
<p>So, you’ve built a robust app that can run against a database locally or on your production server. Great! It’s time to share your application with the world. But what if it is <em>so</em> popular that you have a lot of concurrent users and they are all trying to work with the database at once?</p>
<p>To maintain good application performance, you have to be careful about managing the database connection objects that you create (with <code>DBI::dbConnect()</code>) and to close them when you are doing using them.</p>
<p>If this sounds manual and tedious, you’re in luck! The <a href="https://rstudio.github.io/pool/">{pool}</a> package adds a layer of abstraction to manage a <em>set</em> of connections and execute new queries to an available idle collection. Full examples are given on the package’s website, but in short <code>{pool}</code> is quite easy to implement due to it’s <code>DBI</code>-like syntax. You can replace <code>DBI::dbConenct()</code> with <code>pool::dbPool()</code> and proceed as usual!</p>


</section>
</section>

 ]]></description>
  <category>rstats</category>
  <category>shiny</category>
  <category>data</category>
  <guid>https://emilyriederer.com/post/shiny-db/</guid>
  <pubDate>Sun, 02 Jan 2022 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/shiny-db/featured.png" medium="image" type="image/png" height="107" width="144"/>
</item>
<item>
  <title>Make grouping a first-class citizen in data quality checks</title>
  <dc:creator>Emily Riederer</dc:creator>
  <link>https://emilyriederer.com/post/grouping-data-quality/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://emilyriederer.com/post/grouping-data-quality/featured.jpg" class="img-fluid figure-img"></p>
<figcaption>Photo credit to <a href="https://unsplash.com/@greysonjoralemon">Greyson Joralemon</a> on Unsplash</figcaption>
</figure>
</div>
<p>Which of these numbers doesn’t belong? -1, 0, 1, NA.</p>
<p>It may be hard to tell. If the data in question should be non-negative, -1 is clearly wrong; if it should be complete, the NA is problematic; if it represents the signs to be used in summation, 0 is questionable. In short, there is no data quality without data context.</p>
<p>The past few years have seen an explosion in different solutions for monitoring in-production data quality. These tools, including software like <code>dbt</code> and <code>Great Expectations</code> as well as platforms like <code>Monte Carlo</code>, bring a more DevOps flavor to data production with important functionality like automated testing <em>within</em> pipelines (not just at the end), expressive and configurable semantics for common data checks, and more.</p>
<p>However, despite all these features, I notice a common gap across the landscape which may limit the ability of these tools to encode richer domain context and detect common classes of data failures. I previously wrote about the importance of <a href="https://emilyriederer.netlify.app/post/data-error-gen/">validating data based on its data generating process</a> – both along the technical and conceptual dimensions. Following this logic, an important and lacking functionality<sup>1</sup> across the data quality monitoring landscape, is the ability to readily apply checks separately to groups of data. On a quick survey, I count about 8/14 <code>dbt</code> tests (from the add-on <a href="https://github.com/dbt-labs/dbt-utils">dbt-utils</a> package), 15/37 <a href="https://docs.greatexpectations.io/docs/reference/glossary_of_expectations">Great Expectations</a> column tests, and most all of the <a href="https://docs.getmontecarlo.com/docs/field-health-metrics">Monte Carlo</a> field health metrics that would be improved with first-class grouping functionality. (Lists at the bottom of the post.)</p>
<p>Group-based checks can be important for fully articulating good “business rules” against which to assess data quality. For example, groups could reflect either computationally-relevant dimensions of the ETL process (e.g.&nbsp;data loaded from different sources) or semantically-relevant dimensions of the real-world process that our data captures (e.g.&nbsp;repeated measures pertaining to many individual customers, patients, product lines, etc.)</p>
<p>In this post, I make my case for why grouping should be a first-class citizen in data quality tooling.</p>
<section id="use-cases" class="level2">
<h2 class="anchored" data-anchor-id="use-cases">Use Cases</h2>
<p>There are three main use-cases for enabling easy data quality checks by group: checks that can only be expressed by group, checks that can be more rigorous by group, and checks that are more semantically intuitive by group.</p>
<p><strong>Some checks can be more rigorous by group.</strong> Consider a recency check (i.e.&nbsp;that the maximum date represented in the data is appropriately close to the present.) If the data loads from multiple sources (e.g.&nbsp;customer acquisitions from web and mobile perhaps logging to different source systems), the maximum value of the field could pass the check if any one source loaded, but unless the data is grouped in such a way that reflects different data sources and <em>each</em> group’s maximum date is checked, stale data could go undetected.</p>
<p><strong>Some types of checks can only be expressed by group.</strong> Consider a check for consecutive data values. If a table that measures some sort of user engagements, there might be fields for the <code>USER_ID</code> and <code>MONTHS_SINCE_ACQUISITION</code>. A month counter will most certainly <em>not</em> be strictly increasing across the entire dataset but absolutely should be monotonic within each user.</p>
<p><strong>Some checks are more semantically intuitive by group.</strong> Consider a uniqueness check for the same example as above. The month counter is also not unique across the whole table but could be checked for uniqueness within each user. Group semantics would not be required to accomplish this; a simple <code>USER_ID x MONTHS_SINCE_ACQUISITION</code> composite variable could be produced and checked for uniqueness. However, it feels cumbersome and less semantically meaningful to derive additional fields just to fully check the properties of existing fields. (But for the other two categories, this alone would not justify adding such new features.)</p>
<p>These categories demonstrate the specific use cases for grouped data checks. However, there are also soft benefits.</p>
<p>Most prevalent, having group-based checks be first class citizens opens up a new <a href="https://english.stackexchange.com/questions/77535/what-does-falling-into-the-pit-of-success-mean"><strong>pit of success</strong></a><sup>2</sup>. If you believe, as do I, that this is a often a fundamentally important aspect of confirming data quality and not getting “false promises” (as in the first case where non-grouped checks are less rigorous), configuring checks this way should be as close to zero-friction as possible.</p>
</section>
<section id="demo-nyc-turnstile-data" class="level2">
<h2 class="anchored" data-anchor-id="demo-nyc-turnstile-data">Demo: NYC turnstile data</h2>
<section id="context" class="level3">
<h3 class="anchored" data-anchor-id="context">Context</h3>
<p>To better motivate this need, we will look at a real-world example. For this, I turn to New York City’s <a href="http://web.mta.info/developers/turnstile.html">subway turnstile data</a> which I can always count on to have plenty of data quality quirks (which, to be clear, I do not say as a criticism. There’s nothing unexpected about this in real-world “data as residue” data.)</p>
<p>Specifically, we’ll pull down data extracts for roughly the first quarter of 2020 (published on Jan 11 - April 11, corresponding to weeks ending Jan 10 - April 10.)<sup>3</sup></p>
<p>This data contains 2869965 records, corresponding to one unique record per unique control area (<code>CA</code>), turnstile unit (<code>UNIT</code>), and individual turnstile device (<code>SCP</code>) at internals of four hours of the day.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(dplyr)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(full_data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2869965</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">distinct</span>(full_data, CA, UNIT, SCP, DATE, TIME))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2869965</code></pre>
</div>
</div>
<p>Because this is raw turnstile data, the values for <code>ENTRIES</code> and <code>EXITS</code> may not be what one first expects. These fields contain the <em>cumulative number of turns of the turnstile</em> since it was last zeroed-out. Thus, to get the actual number of <em>incremental</em> entries during a given time period, one must take the difference between the current and previous number of entries <em>at the turnstile level</em>. Thus, missing or corrupted values<sup>4</sup> could cascade in unpredictable ways throughout the transformation process.</p>
<p>Looking at the data for a single turnstile unit makes the way this data is encoded more clear:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">full_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(CA <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A002"</span>, </span>
<span id="cb5-3">         UNIT <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R051"</span>, </span>
<span id="cb5-4">         SCP <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"02-00-00"</span>, </span>
<span id="cb5-5">         DATE <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2020-01-04"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">arrange</span>(TIME) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(TIME, ENTRIES, EXITS)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 x 3
  TIME       ENTRIES   EXITS
  &lt;hms&gt;        &lt;int&gt;   &lt;int&gt;
1 10800 secs 7331213 2484849
2 25200 secs 7331224 2484861
3 39600 secs 7331281 2484936
4 54000 secs 7331454 2485014
5 68400 secs 7331759 2485106
6 82800 secs 7331951 2485166</code></pre>
</div>
</div>
</section>
<section id="quality-checks" class="level3">
<h3 class="anchored" data-anchor-id="quality-checks">Quality checks</h3>
<p>So how does this map to the use cases above?</p>
<p>First, lets consider checks that are <strong>more rigorous by group</strong>. One example of this is checking for completeness of the range of data.</p>
<p>Looking at the aggregate level, the data appears complete. The minimum data is the correct start date for the week ending Jan 10 and the maximum date is the correct end date for the week ending April 10.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(full_data,</span>
<span id="cb7-2">          <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">min</span>(DATE),</span>
<span id="cb7-3">          <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(DATE))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 x 2
  `min(DATE)` `max(DATE)`
  &lt;date&gt;      &lt;date&gt;     
1 2020-01-04  2020-04-10 </code></pre>
</div>
</div>
<p>This check might provide a false sense of security.</p>
<p>However, what happens if we repeat this check at the actual grain of records which we <em>need</em> to be complete and subsequent calculations probably assume<sup>5</sup> are complete? We find many individual units whose data does not appear appropriately recent.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">full_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(CA, UNIT, SCP) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">MAX =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(DATE)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(MAX <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2020-04-10"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`summarise()` has grouped output by 'CA', 'UNIT'. You can override using the
`.groups` argument.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 54 x 4
# Groups:   CA, UNIT [24]
   CA    UNIT  SCP      MAX       
   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;date&gt;    
 1 C021  R212  00-00-00 2020-01-06
 2 C021  R212  00-00-01 2020-01-06
 3 C021  R212  00-00-02 2020-01-06
 4 C021  R212  00-00-03 2020-01-06
 5 H007  R248  00-00-00 2020-03-07
 6 H007  R248  00-00-01 2020-02-15
 7 H007  R248  00-03-00 2020-02-15
 8 H007  R248  00-03-01 2020-02-15
 9 H007  R248  00-03-02 2020-02-15
10 H009  R235  00-03-04 2020-03-20
# i 44 more rows</code></pre>
</div>
</div>
<p>Next, consider checks that are <strong>only expressible by group</strong>. One example of this is a monotonicity (value always increasing) check.</p>
<p>For example, <code>ENTRIES</code> is certainly <em>not</em> monotonically increasing at the row level. Each individual turnstile device is counting up according to its own usage. However, in an ideal world, these fields should be monotonic over time at the level of individual devices. (Spoiler alert: due to the maintenance, malfunction, and maxing-out scenarios mentioned above, it’s not.) Thus, this type of check is only possible at the grouped level.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">full_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(CA, UNIT, SCP) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">arrange</span>(DATE, TIME) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">LAG_ENTRIES =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lag</span>(ENTRIES)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(ENTRIES <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> LAG_ENTRIES, DATE <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-01-25'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(CA, UNIT, SCP, DATE, TIME, ENTRIES, LAG_ENTRIES) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">arrange</span>(ENTRIES <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> LAG_ENTRIES)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 19,281 x 7
# Groups:   CA, UNIT, SCP [262]
   CA    UNIT  SCP      DATE       TIME        ENTRIES LAG_ENTRIES
   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;date&gt;     &lt;hms&gt;         &lt;int&gt;       &lt;int&gt;
 1 R231  R176  00-00-05 2020-03-09 75600 secs       99  1054865694
 2 R412  R146  00-03-03 2020-02-04 43200 secs 51627403   318991420
 3 N029  R333  01-00-00 2020-03-15 75600 secs       18   168628048
 4 R327  R361  01-06-00 2020-03-03 72000 secs   524397   135382887
 5 R312  R405  00-05-00 2020-02-16 57600 secs   131089   118174528
 6 N091  R029  02-05-00 2020-02-01 54000 secs   524368   118146213
 7 A025  R023  01-06-00 2020-03-04 82800 secs 11525743    67822764
 8 A025  R023  01-00-00 2020-03-04 82800 secs  5276291    28448967
 9 R238  R046  00-03-00 2020-02-15 82800 secs        5    16336060
10 R533  R055  00-03-04 2020-03-14 43200 secs      104    15209650
# i 19,271 more rows</code></pre>
</div>
</div>
</section>
</section>
<section id="alternatives-considered" class="level2">
<h2 class="anchored" data-anchor-id="alternatives-considered">Alternatives Considered</h2>
<p>Given that this post is, to some extent, a feature request across all data quality tools ever, it’s only polite to discuss downsides and alternative solutions that I considered. Clearly, finer-grained checks incur a greater computational cost and could, in some cases, be achieved via other means.</p>
<p><strong>Grouped data check might seem excessive.</strong> After all, data quality checks do not, perhaps, aim to guarantee every field is 100% correct. Rather, they are higher-level metrics which aim to catch signals of deeper issues. My counterargument is largely based in the first use case listed above. Without testing data at the right level of granularity, checks could almost do more harm than good if they promote a false sense of data quality by masking issues.</p>
<p><strong>Not all grains of data are equally likely to break.</strong> Taking the previous point into account, we likely cannot check everything, so we ought to focus our attention on some combination of the most “important” errors and the most “likely” errors. In the subway example, turnstile-level failures are likely because each individual turnstile is a sensor that is independently involved in the <em>data collection process</em> and can break in its own unique ways. However, for something like a clickstream for different users on a website, the data collection process is centralized, so it would be less like (and infeasible to check) for individual customer-level data to break in dramatically different ways.</p>
<p><strong>High-risk grouped data is possibly ungrouped further upstream.</strong> Following the logic that grouped data is more dangerous if groups denote units responsible for their own data collection, in theory this data is being transmitted separately at some point in the pipeline. Thus, in some cases it could be checked before it is grouped. However, we cannot always get infinitely far upstream in the data pipeline as some pieces may be outside of our control or produced atomically by a third-party platform.</p>
<p><strong>Some grouped checks can be achieved in other ways.</strong> Some (but not all) of these checks can be mocked by creating composite variables, using other built-in features<sup>6</sup>, or writing custom checks <sup>7</sup>. However, there solutions seem to defy part of the benefits of these tools: semantically meaningful checks wrapped in readable syntax and ready for use out-of-the-box. This also implies that grouped operations are far less than first-class citizens. This also limits the ability to make use of some of the excellent functionality these tools offer for documenting data quality checks in metadata and reporting on their outcomes.</p>
<p>I also considered the possibility that this is a niche, personal need moreso than a general one because I work with a <em>lot</em> of panel data. However, I generally believe <em>most</em> data is nested in some way. I can at least confirm that I’ve not completely alone in this desire with a peak at GitHub issue feature requests in different data quality tools. For example, three stale stale GitHub issues on the <code>Great Expectations</code> repo (<a href="https://github.com/great-expectations/great_expectations/issues/351">1</a>, <a href="https://github.com/great-expectations/great_expectations/issues/402">2</a>, <a href="https://github.com/great-expectations/great_expectations/issues/373">3</a>) request similar functionality.</p>
</section>
<section id="downsides" class="level2">
<h2 class="anchored" data-anchor-id="downsides">Downsides</h2>
<p>There’s no such thing as a free lunch or a free feature enhancement. My point is in no way to criticize existing data quality tools that do not have this functionality. Designing any tool is a process of trade-offs, and it’s only fair to discuss the downsides. These issues are exacerbated further when adding “just one more thing” to mature, heavily used tools as opposed to developing new ones.</p>
<p><strong>Grouped checks are more computational expensive.</strong> Partitioning and grouping can make data check operations more expensive by disabling certain computational shortcuts<sup>8</sup> and requiring more total data to be retained. This is particularly true if the data is indexed or partitioned along different dimensions than the groups used for checks. The extra time required to run more fine-grained checks could become intractable or at least unappealing, particularly in an interactive or continuous integration context. However, in many cases it could be a better use of time to more rigorously test recently loaded data as opposed to (or in conjunction with) running higher-level checks across larger swaths of data.</p>
<p><strong>API bloat makes tools less navigable.</strong> Any new feature has to be documented by developers and comprehended by users. Having too many “first-class citizen” features can lead to features being ignored, unknown, or misused. It’s easy to point to any one feature in isolation and claim it is important; it’s much harder to stare at a full backlog and decide where the benefits are worth the cost.</p>
<p><strong>Incremental functionality adds more overhead.</strong> Every new feature demands careful programming and testing. Beyond that, there’s a substantial mental tax in thinking through how that feature needs to interact with existing functionality while, at the same time, preserving backwards compatibility.</p>
<p><strong>Every feature built means a different one isn’t.</strong> As a software user, it’s easy to have a great idea for a feature that should absolutely be added. That’s a far different challenge than that faced by the developers and maintainers who must prioritize a rich backlog full of competing priorities.</p>
</section>
<section id="survey-of-available-tools" class="level2">
<h2 class="anchored" data-anchor-id="survey-of-available-tools">Survey of available tools</h2>
<p>My goal is in no way to critique any of the amazing, feature-rich data quality tools available today. However, to further illustrate my point, I pulled down key data checks from a few prominent packages to assess how many of their tests would be potentially enhanced with the ability to provided grouping parameters. Below are lists for <code>dbt-utils</code>, <code>Great Expectations</code>, and <code>Monte Carlo</code> with relevant tests <em>in bold</em>.</p>
<section id="dbt-utils-8-14" class="level3">
<h3 class="anchored" data-anchor-id="dbt-utils-8-14">dbt-utils (8 / 14)</h3>
<ul>
<li><strong>equal_rowcount</strong></li>
<li>equality</li>
<li>expression_is_true</li>
<li><strong>recency</strong><br>
</li>
<li><strong>at_least_one</strong></li>
<li><strong>not_constant</strong></li>
<li><strong>cardinality_equality</strong></li>
<li><strong>unique_where</strong></li>
<li>not_null_where<br>
</li>
<li><strong>not_null_proportion</strong></li>
<li>relationships_where</li>
<li>mutually_exclusive_ranges</li>
<li><strong>unique_combination_of_columns</strong> (<em>but less important - only for semantics</em>)</li>
<li>accepted_range</li>
</ul>
</section>
<section id="great-expectations-15-37" class="level3">
<h3 class="anchored" data-anchor-id="great-expectations-15-37">Great Expectations (15 / 37)</h3>
<ul>
<li><strong>expect_column_values_to_be_unique</strong> (<em>but less important - only for semantics</em>)</li>
<li>expect_column_values_to_not_be_null<br>
</li>
<li>expect_column_values_to_be_null<br>
</li>
<li>expect_column_values_to_be_of_type<br>
</li>
<li>expect_column_values_to_be_in_type_list</li>
<li>expect_column_values_to_be_in_set</li>
<li>expect_column_values_to_not_be_in_set</li>
<li>expect_column_values_to_be_between<br>
</li>
<li><strong>expect_column_values_to_be_increasing</strong></li>
<li><strong>expect_column_values_to_be_decreasing</strong></li>
<li>expect_column_value_lengths_to_be_between</li>
<li>expect_column_value_lengths_to_equal</li>
<li>expect_column_values_to_match_regex</li>
<li>expect_column_values_to_not_match_regex</li>
<li>expect_column_values_to_match_regex_list</li>
<li>expect_column_values_to_not_match_regex_list</li>
<li>expect_column_values_to_match_like_pattern</li>
<li>expect_column_values_to_not_match_like_pattern</li>
<li>expect_column_values_to_match_like_pattern_list</li>
<li>expect_column_values_to_not_match_like_pattern_list</li>
<li>expect_column_values_to_match_strftime_format</li>
<li>expect_column_values_to_be_dateutil_parseable</li>
<li>expect_column_values_to_be_json_parseable</li>
<li>expect_column_values_to_match_json_schema</li>
<li>expect_column_distinct_values_to_be_in_set</li>
<li><strong>expect_column_distinct_values_to_contain_set</strong></li>
<li><strong>expect_column_distinct_values_to_equal_set</strong></li>
<li><strong>expect_column_mean_to_be_between</strong></li>
<li><strong>expect_column_median_to_be_between</strong></li>
<li><strong>expect_column_quantile_values_to_be_between</strong></li>
<li><strong>expect_column_stdev_to_be_between</strong></li>
<li><strong>expect_column_unique_value_count_to_be_between</strong></li>
<li><strong>expect_column_proportion_of_unique_values_to_be_between</strong></li>
<li><strong>expect_column_most_common_value_to_be_in_set</strong></li>
<li><strong>expect_column_max_to_be_between</strong></li>
<li><strong>expect_column_min_to_be_between</strong></li>
<li><strong>expect_column_sum_to_be_between</strong></li>
</ul>
</section>
<section id="monte-carlo-all" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-all">Monte Carlo (All)</h3>
<p>Any of Monte Carlo’s checks might be more sensitive to detecting changes with subgrouping. Since these “health metrics” tend to represent distributional properties, it can be useful to ensure that “good groups” aren’t pulling down the average value and masking errors in “bad groups”.</p>
<ul>
<li>Pct NUll<br>
</li>
<li>Pct Unique</li>
<li>Pct Zero<br>
</li>
<li>Pct Negative<br>
</li>
<li>Min</li>
<li>p20</li>
<li>p40</li>
<li>p60</li>
<li>p80</li>
<li>Mean</li>
<li>Std</li>
<li>Max</li>
<li>Pct Whitespace</li>
<li>Pct Integer</li>
<li>Pct “Null”/“None”</li>
<li>Pct Float</li>
<li>Pct UUID</li>
</ul>
</section>
</section>
<section id="code-appendix" class="level2">
<h2 class="anchored" data-anchor-id="code-appendix">Code Appendix</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data source: http://web.mta.info/developers/turnstile.html</span></span>
<span id="cb14-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb14-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(readr)</span>
<span id="cb14-4"></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define read function with schema ----</span></span>
<span id="cb14-6">read_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(url) {</span>
<span id="cb14-7">  </span>
<span id="cb14-8">  readr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_csv</span>(url,</span>
<span id="cb14-9">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col_names =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb14-10">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col_types =</span></span>
<span id="cb14-11">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cols</span>(</span>
<span id="cb14-12">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">C/A</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-13">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">UNIT =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-14">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">SCP =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-15">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">STATION =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-16">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">LINENAME =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-17">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">DIVISION =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-18">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">DATE =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_date</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">format =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%m/%d/%Y"</span>),</span>
<span id="cb14-19">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">TIME =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_time</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">format =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>),</span>
<span id="cb14-20">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">DESC =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_character</span>(),</span>
<span id="cb14-21">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ENTRIES =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_integer</span>(),</span>
<span id="cb14-22">                      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">EXITS =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">col_integer</span>()</span>
<span id="cb14-23">                    ))</span>
<span id="cb14-24">  </span>
<span id="cb14-25">}</span>
<span id="cb14-26"></span>
<span id="cb14-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ridership data ----</span></span>
<span id="cb14-28">dates <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq.Date</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">from =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-01-11'</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">to =</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-04-11'</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'7 days'</span>)</span>
<span id="cb14-29">dates_str <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(dates, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">format =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'%y%m%d'</span>)</span>
<span id="cb14-30">dates_url <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sprintf</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'http://web.mta.info/developers/data/nyct/turnstile/turnstile_%s.txt'</span>, dates_str)</span>
<span id="cb14-31">datasets <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lapply</span>(dates_url, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">FUN =</span> read_data)</span>
<span id="cb14-32">full_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">do.call</span>(rbind, datasets)</span>
<span id="cb14-33">full_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> full_data[full_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>DESC <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"REGULAR"</span>,]</span>
<span id="cb14-34"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(full_data)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CA"</span></span></code></pre></div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>With the exception of <code>pointblank</code> which kindly entertained an issue I opened on this topic: https://github.com/rich-iannone/pointblank/issues/300↩︎</p></li>
<li id="fn2"><p>The “pit of success” is the idea that well-designed tools can help nudge people to do the “right” thing by default because its also the easiest. I first learned of it in a talk by Hadley Wickham, and it is originally attributed to Microsoft program manage Rico Mariani.↩︎</p></li>
<li id="fn3"><p>Code for this pull is at the bottom of the post.↩︎</p></li>
<li id="fn4"><p>This can happen for many reasons including turnstile maintenance or replacement. My goal in this post is not to go into all of the nuances of this particular dataset, of which much has already been written, so I’m simplifying somewhat to keep it as a tractable motivating example.↩︎</p></li>
<li id="fn5"><p>Transformations should probably never assume this. Any real ETL process using this data would like have to account for incompleteness in an automated fashion because it really is not a rare event. Again, we are simplifying here for the sake of example↩︎</p></li>
<li id="fn6"><p>For example, Great Expectations does offer conditional expectations which can be executed on manually-specified subsets of data. This could be a tractable solution for applying data checks to a small number of categorical variables, but less so for large or ill-defined categories like user IDs. More here: https://legacy.docs.greatexpectations.io/en/latest/reference/core_concepts/conditional_expectations.html↩︎</p></li>
<li id="fn7"><p>Like, in the case of <code>Great Expectation</code>’s python-based API, writing custom code to partition data before applying checks, or, in the case of <code>dbt</code>/<code>dbt-utils</code> writing a custom macro.↩︎</p></li>
<li id="fn8"><p>For example, the maximum of a set of numbers is the maximum of the maximums of the subsets. Thus, if my data is distributed, I can find the max by comparing only summary statistics from the distributed subsets instead of pulling all of the raw data back together.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>data</category>
  <guid>https://emilyriederer.com/post/grouping-data-quality/</guid>
  <pubDate>Sat, 27 Nov 2021 06:00:00 GMT</pubDate>
  <media:content url="https://emilyriederer.com/post/grouping-data-quality/featured.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
